{
    "nbformat_minor": 2, 
    "cells": [
        {
            "source": "# Fraud Detection with XGBoost and Machine Learning in DSX Local\n<a id='toc'></a>", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "The purpose of this notebook:\n1. Showcase how to build and deploy a XGBoost Model in DSX Local.\n2. Share our experiences with XGB and SMOTE. The project originates from a SPSS Modeler stream with which we wanted to showcase how coders and non-coders could work together in DSX environment. But we saw different output with same data and 'same' settings(as we assumed, but there are some 'bugs' we did not notice at first, we will cover it later in the notebook).\n\nNote: The data is simulated for demo purpose only.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "\n1. [Imports](#Imports)\n2. [Load Data](#Load Data)\n3. [Exploratory Data Analysis](#eda)\n4. [Split into Training and Test](#Split into Training and Test)\n5. [Handle Imbalance using SMOTE(only on Training set)](#Handle Imbalance using SMOTE)\n6. [XGboost](#xgboost)  \n    6.1 [Build Pipeline](#ppl)  \n    6.2 [Plot Feature Importance](#imp)  \n    6.3 [Model Evaluation](#eva)      \n7. [Model Deployment using DSX Machine Learning](#deploy)  \n    7.1 [Online Scoring](#online)  \n    7.2 [Batch Scoring](#batch)  ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<a id='Imports'></a>\n## Imports\n<div style=\"text-align: right\"> [Top](#toc) </div>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 249, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "0.7.post3\n"
                }
            ], 
            "source": "import xgboost as xgb\nprint(xgboost.__version__)\n\nimport numpy as np\nimport pandas as pd\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import roc_auc_score, confusion_matrix, classification_report\nfrom sklearn.model_selection import GridSearchCV,RandomizedSearchCV\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import LabelBinarizer, StandardScaler\nfrom sklearn_pandas import DataFrameMapper\n\nimport brunel\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport matplotlib.pyplot as plt\n%matplotlib inline"
        }, 
        {
            "source": "<a id='Load Data'></a>\n## Load Data\n<div style=\"text-align: right\"> [Top](#toc) </div>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 240, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 240, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dollar_Amount</th>\n      <th>Transaction_Type</th>\n      <th>Store_Type</th>\n      <th>Cardholder_Region</th>\n      <th>Country</th>\n      <th>Fraudulent</th>\n      <th>Last3hourTransactions</th>\n      <th>Hours_Since_Last_Transaction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>188.56</td>\n      <td>swiped</td>\n      <td>ATM Withdrawal</td>\n      <td>E</td>\n      <td>USA</td>\n      <td>F</td>\n      <td>4</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>160.54</td>\n      <td>keyed</td>\n      <td>Grocery</td>\n      <td>NE</td>\n      <td>Australia</td>\n      <td>F</td>\n      <td>3</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>153.24</td>\n      <td>swiped</td>\n      <td>Retail - Pharmacy</td>\n      <td>SW</td>\n      <td>European Union</td>\n      <td>T</td>\n      <td>2</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>148.66</td>\n      <td>keyed</td>\n      <td>Communications - telephone and wireless</td>\n      <td>NW</td>\n      <td>USA</td>\n      <td>F</td>\n      <td>1</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>174.03</td>\n      <td>keyed</td>\n      <td>Spa/Beauty</td>\n      <td>SW</td>\n      <td>Asia</td>\n      <td>F</td>\n      <td>1</td>\n      <td>25</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "   Dollar_Amount Transaction_Type                               Store_Type  \\\n0         188.56           swiped                           ATM Withdrawal   \n1         160.54            keyed                                  Grocery   \n2         153.24           swiped                        Retail - Pharmacy   \n3         148.66            keyed  Communications - telephone and wireless   \n4         174.03            keyed                               Spa/Beauty   \n\n  Cardholder_Region         Country Fraudulent  Last3hourTransactions  \\\n0                 E             USA          F                      4   \n1                NE       Australia          F                      3   \n2                SW  European Union          T                      2   \n3                NW             USA          F                      1   \n4                SW            Asia          F                      1   \n\n   Hours_Since_Last_Transaction  \n0                            21  \n1                            21  \n2                            21  \n3                            35  \n4                            25  "
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "# The code was removed by DSX for sharing."
        }, 
        {
            "execution_count": 8, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 8, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dollar_Amount</th>\n      <th>Transaction_Type</th>\n      <th>Store_Type</th>\n      <th>Cardholder_Region</th>\n      <th>Country</th>\n      <th>Fraudulent</th>\n      <th>Last3hourTransactions</th>\n      <th>Hours_Since_Last_Transaction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>188.56</td>\n      <td>swiped</td>\n      <td>ATM Withdrawal</td>\n      <td>E</td>\n      <td>USA</td>\n      <td>F</td>\n      <td>4</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>160.54</td>\n      <td>keyed</td>\n      <td>Grocery</td>\n      <td>NE</td>\n      <td>Australia</td>\n      <td>F</td>\n      <td>3</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>153.24</td>\n      <td>swiped</td>\n      <td>Retail - Pharmacy</td>\n      <td>SW</td>\n      <td>European Union</td>\n      <td>T</td>\n      <td>2</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>148.66</td>\n      <td>keyed</td>\n      <td>Communications - telephone and wireless</td>\n      <td>NW</td>\n      <td>USA</td>\n      <td>F</td>\n      <td>1</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>174.03</td>\n      <td>keyed</td>\n      <td>Spa/Beauty</td>\n      <td>SW</td>\n      <td>Asia</td>\n      <td>F</td>\n      <td>1</td>\n      <td>25</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "   Dollar_Amount Transaction_Type                               Store_Type  \\\n0         188.56           swiped                           ATM Withdrawal   \n1         160.54            keyed                                  Grocery   \n2         153.24           swiped                        Retail - Pharmacy   \n3         148.66            keyed  Communications - telephone and wireless   \n4         174.03            keyed                               Spa/Beauty   \n\n  Cardholder_Region         Country Fraudulent  Last3hourTransactions  \\\n0                 E             USA          F                      4   \n1                NE       Australia          F                      3   \n2                SW  European Union          T                      2   \n3                NW             USA          F                      1   \n4                SW            Asia          F                      1   \n\n   Hours_Since_Last_Transaction  \n0                            21  \n1                            21  \n2                            21  \n3                            35  \n4                            25  "
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "import os, pandas as pd\n# Add asset from file system\ndf_data_1 = pd.read_csv(os.environ['DSX_PROJECT_DIR']+'/datasets/History_Transactions_v4.csv')\n# only keep variables we will use later\ndf_data_1 = df_data_1[['Dollar_Amount', \n                       'Transaction_Type',\n                       'Store_Type', \n                       'Cardholder_Region', \n                       'Country',\n                       'Fraudulent',\n                       'Last3hourTransactions',\n                       'Hours_Since_Last_Transaction'\n                      ]]\ndf_data_1.head()"
        }, 
        {
            "source": "<a id='eda'></a>\n## Exploratory Data Analysis\n<div style=\"text-align: right\"> [Top](#toc) </div>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "The data is actually well cleaned so we will just focus on the SMOTE and XGB, and keep data prep and EDA to minimal.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 3, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "Dollar_Amount                   0\nTransaction_Type                0\nStore_Type                      0\nCardholder_Region               0\nCountry                         0\nFraudulent                      0\nLast3hourTransactions           0\nHours_Since_Last_Transaction    0\ndtype: int64"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "# check missing\ndf_data_1.apply(lambda x: sum(x.isnull()))"
        }, 
        {
            "execution_count": 4, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "****************************************\n\nFrequency count for variable Fraudulent\nF    52132\nT     2903\nName: Fraudulent, dtype: int64\n****************************************\n\nFrequency count for variable Transaction_Type\nswiped    27623\nkeyed     27412\nName: Transaction_Type, dtype: int64\n****************************************\n\nFrequency count for variable Store_Type\nRestaurant                                 4470\nProfessional Services                      3443\nGrocery                                    3403\nGas                                        3261\nOther                                      3226\nHotel                                      3206\nRetail - Apparel                           2276\nATM Withdrawal                             2240\nRetail - Furniture                         2232\nEntertainment and Arts                     2207\nRetail - Home Improvement                  2194\nRetail - Drug Store                        2193\nCommunications - telephone and wireless    2191\nMedical                                    2181\nRetail - Home Electronics                  2161\nRetail - Pharmacy                          2127\nRetail - Toys                              1134\nEducation and Instruction                  1129\nRetail - Floral                            1110\nUtilities                                  1107\nRetail - Weapons                           1102\nRetail - Office and School Supplies        1097\ne-Retail                                   1095\nRetail - Convenience Store                 1093\nRetail - Books                             1081\nRetail - Jewelry and Watches               1057\nSpa/Beauty                                 1019\nName: Store_Type, dtype: int64\n****************************************\n\nFrequency count for variable Cardholder_Region\nE     7139\nN     6946\nNE    6915\nS     6896\nW     6830\nSW    6804\nSE    6763\nNW    6742\nName: Cardholder_Region, dtype: int64\n****************************************\n\nFrequency count for variable Country\nUSA               27728\nAsia               9239\nEuropean Union     9064\nAustralia          9004\nName: Country, dtype: int64\n"
                }
            ], 
            "source": "# Look at categorical variables\nvar = ['Fraudulent', 'Transaction_Type', 'Store_Type', 'Cardholder_Region', 'Country']\nfor v in var:\n    print(\"****************************************\")\n    print('\\nFrequency count for variable %s'%v)\n    print(df_data_1[v].value_counts())"
        }, 
        {
            "source": "## Split into Training and Test", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 241, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Number of training records: 44028\nTraining: T = : 2304\nTraining: F = : 41724\nNumber of testing records : 11007\nTesting: T = : 599\nTesting: F = : 10408\n"
                }
            ], 
            "source": "y = df_data_1['Fraudulent'].map(lambda l: 1 if l == 'T' else 0)\nX = df_data_1.drop(['Fraudulent'], axis=1)\n\nfrom sklearn.cross_validation import train_test_split \n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234567)\n\nprint(\"Number of training records: \" + str(len(X_train)))\nprint(\"Training: T = : \" + str(sum(y_train)))\nprint(\"Training: F = : \" + str(len(X_train) - sum(y_train)))\nprint(\"Number of testing records : \" + str(len(X_test)))\nprint(\"Testing: T = : \" + str(sum(y_test)))\nprint(\"Testing: F = : \" + str(len(X_test) - sum(y_test)))"
        }, 
        {
            "source": "The data is imbalanced. We used SMOTE to handle the imbalance. ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## Handle Imbalance using SMOTE(only on Training set)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 12, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Collecting imblearn\n  Downloading imblearn-0.0-py2.py3-none-any.whl\nCollecting imbalanced-learn (from imblearn)\n  Downloading imbalanced_learn-0.3.3-py3-none-any.whl (144kB)\n\u001b[K    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 153kB 995kB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.5/site-packages (from imbalanced-learn->imblearn)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.5/site-packages (from imbalanced-learn->imblearn)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.5/site-packages (from imbalanced-learn->imblearn)\nInstalling collected packages: imbalanced-learn, imblearn\nSuccessfully installed imbalanced-learn-0.3.3 imblearn-0.0\n"
                }
            ], 
            "source": "!pip install imblearn"
        }, 
        {
            "execution_count": 242, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# restart kernel if see error\nfrom imblearn.over_sampling import SMOTE"
        }, 
        {
            "execution_count": 243, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Fraud/Non-Fraud Ratio Before SMOTE: 0.05233033524121014\nFraud/Non-Fraud Ratio After SMOTE: 0.5\nFraud in Training after SMOTE = T: 41724\nFraud in Training after SMOTE = F: 41724\n\n************Test Set************\n\nNumber of testing records : 11007\nTraining: T = : 599\nTraining: F = :10408\n"
                }
            ], 
            "source": "X_train_dummy = pd.get_dummies(X_train)\nsm = SMOTE(random_state=2662761, ratio = 'auto', k_neighbors = 5)\nX_train_res, y_train_res = sm.fit_sample(X_train_dummy, y_train)\n#smote only deals with continuous variable\nX_train_res_rounded = X_train_res.round()\n\n\nprint('Fraud/Non-Fraud Ratio Before SMOTE: ' + str(y_train.sum()/len(y_train)))\nprint('Fraud/Non-Fraud Ratio After SMOTE: ' + str(y_train_res.sum()/len(y_train_res)))\n\nprint(\"Fraud in Training after SMOTE = T: \" + str(sum(y_train_res)))\nprint(\"Fraud in Training after SMOTE = F: \" + str(len(y_train_res) - sum(y_train_res)))\nprint(\"\\n************Test Set************\\n\")\nprint(\"Number of testing records : \" + str(len(X_test)))\nprint(\"Training: T = : \" + str(sum(y_test)))\nprint(\"Training: F = :\" + str(len(y_test) - sum(y_test)))"
        }, 
        {
            "source": "** Important Note: currently SMOTE from imblearn only supports continuous variable, we rounded generated values to 0/1 for binary variables as a walk-around. See discussions [here](https://github.com/scikit-learn-contrib/imbalanced-learn/issues/401). This is the root cause for the difference between Modeler and Notebook, although we are not sure if Modeler has adopted more sophisticated solution to handle categorical variables. ** ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 244, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# currently SMOTE from imblearn only supports continuous variable only, round generated value to 0/1 for binary variables as a walkaround\nfor i in range(len(X_train_res)):\n    X_train_res[i][1:] = X_train_res[i][1:].round()"
        }, 
        {
            "execution_count": 246, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# in order to build pipeline, we need to reverse the matrix returned by SMOTE to df\nX_train_df = pd.DataFrame(X_train_res)\nX_train_df.columns = pd.get_dummies(X_train).columns.tolist()\n\nX_train_df['Transaction_Type'] = X_train_df[['Transaction_Type_keyed', 'Transaction_Type_swiped']].idxmax(axis=1).map(lambda l: l.replace('Transaction_Type_', ''))\nX_train_df['Store_Type'] = X_train_df[['Store_Type_ATM Withdrawal',\n       'Store_Type_Communications - telephone and wireless',\n       'Store_Type_Education and Instruction',\n       'Store_Type_Entertainment and Arts', 'Store_Type_Gas',\n       'Store_Type_Grocery', 'Store_Type_Hotel', 'Store_Type_Medical',\n       'Store_Type_Other', 'Store_Type_Professional Services',\n       'Store_Type_Restaurant', 'Store_Type_Retail - Apparel',\n       'Store_Type_Retail - Books', 'Store_Type_Retail - Convenience Store',\n       'Store_Type_Retail - Drug Store', 'Store_Type_Retail - Floral',\n       'Store_Type_Retail - Furniture', 'Store_Type_Retail - Home Electronics',\n       'Store_Type_Retail - Home Improvement',\n       'Store_Type_Retail - Jewelry and Watches',\n       'Store_Type_Retail - Office and School Supplies',\n       'Store_Type_Retail - Pharmacy', 'Store_Type_Retail - Toys',\n       'Store_Type_Retail - Weapons', 'Store_Type_Spa/Beauty',\n       'Store_Type_Utilities', 'Store_Type_e-Retail']].idxmax(axis=1).map(lambda l: l.replace('Store_Type_', ''))\n\nX_train_df['Country'] = X_train_df[['Country_Asia', 'Country_Australia',\n       'Country_European Union', 'Country_USA']].idxmax(axis=1).map(lambda l: l.replace('Country_', ''))\n\nX_train_df['Cardholder_Region'] = X_train_df[['Cardholder_Region_E',\n       'Cardholder_Region_N', 'Cardholder_Region_NE', 'Cardholder_Region_NW',\n       'Cardholder_Region_S', 'Cardholder_Region_SE', 'Cardholder_Region_SW',\n       'Cardholder_Region_W']].idxmax(axis=1).map(lambda l: l.replace('Cardholder_Region_', ''))\n\nX_train_df = X_train_df.drop(['Transaction_Type_keyed', 'Transaction_Type_swiped', 'Store_Type_ATM Withdrawal',\n       'Store_Type_Communications - telephone and wireless',\n       'Store_Type_Education and Instruction',\n       'Store_Type_Entertainment and Arts', 'Store_Type_Gas',\n       'Store_Type_Grocery', 'Store_Type_Hotel', 'Store_Type_Medical',\n       'Store_Type_Other', 'Store_Type_Professional Services',\n       'Store_Type_Restaurant', 'Store_Type_Retail - Apparel',\n       'Store_Type_Retail - Books', 'Store_Type_Retail - Convenience Store',\n       'Store_Type_Retail - Drug Store', 'Store_Type_Retail - Floral',\n       'Store_Type_Retail - Furniture', 'Store_Type_Retail - Home Electronics',\n       'Store_Type_Retail - Home Improvement',\n       'Store_Type_Retail - Jewelry and Watches',\n       'Store_Type_Retail - Office and School Supplies',\n       'Store_Type_Retail - Pharmacy', 'Store_Type_Retail - Toys',\n       'Store_Type_Retail - Weapons', 'Store_Type_Spa/Beauty',\n       'Store_Type_Utilities', 'Store_Type_e-Retail', 'Country_Asia', 'Country_Australia',\n       'Country_European Union', 'Country_USA', 'Cardholder_Region_E',\n       'Cardholder_Region_N', 'Cardholder_Region_NE', 'Cardholder_Region_NW',\n       'Cardholder_Region_S', 'Cardholder_Region_SE', 'Cardholder_Region_SW',\n       'Cardholder_Region_W'], 1)"
        }, 
        {
            "source": "## XGboost", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### Baseline: Default Setting from Modeler", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Let's start with the default parameters from Modeler.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 250, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "mapper1 = DataFrameMapper(\n    [(['Dollar_Amount'], None),\n     (['Last3hourTransactions'], None),\n     (['Hours_Since_Last_Transaction'], None),\n     ('Transaction_Type', LabelBinarizer()), # for binary, only one variable generated\n     ('Store_Type', LabelBinarizer()),\n     ('Cardholder_Region', LabelBinarizer()),\n     ('Country', LabelBinarizer())\n     ])"
        }, 
        {
            "execution_count": 253, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "X_train_res_maptrsfm = mapper1.fit_transform(X_train_df)\nX_test_maptrsfm = mapper1.fit_transform(X_test)"
        }, 
        {
            "execution_count": 255, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "xgb_model_spss = XGBClassifier(\n    tree_method= \"auto\",\n    n_estimators = 10, \n    max_depth = 6,\n    min_child_weight = 1.0,\n    max_delta_step = 0.0,\n    objective = \"binary:logistic\",\n    seed = 6924827,\n    subsample = 1.0,\n    learning_rate = .3, # fixed\n    gamma = 0.0,\n    colsample_bytree = 1.0,\n    colsample_bylevel = 1.0,\n    reg_lambda = 1.0,\n    reg_alpha = 0.0,\n    scale_pos_weight = 1.0)"
        }, 
        {
            "execution_count": 256, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 256, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,\n       colsample_bytree=1.0, gamma=0.0, learning_rate=0.3,\n       max_delta_step=0.0, max_depth=6, min_child_weight=1.0, missing=None,\n       n_estimators=10, n_jobs=1, nthread=None,\n       objective='binary:logistic', random_state=0, reg_alpha=0.0,\n       reg_lambda=1.0, scale_pos_weight=1.0, seed=6924827, silent=True,\n       subsample=1.0, tree_method='auto')"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "xgb_model_spss.fit(X_train_res_maptrsfm, y_train_res)"
        }, 
        {
            "execution_count": 257, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "pred_spss = xgb_model_spss.predict(X_test_maptrsfm)"
        }, 
        {
            "execution_count": 258, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "*****Confusion Matrix *****\n[[6726 3682]\n [ 244  355]]\n*****Classification Report*****\n             precision    recall  f1-score   support\n\n          0       0.96      0.65      0.77     10408\n          1       0.09      0.59      0.15       599\n\navg / total       0.92      0.64      0.74     11007\n\nROC: 0.6194440452252601\n"
                }
            ], 
            "source": "roc_spss = roc_auc_score(y_test, pred_spss)\nprint(\"*****Confusion Matrix *****\")\nprint(confusion_matrix(y_test, pred_spss))\nprint(\"*****Classification Report*****\")\nprint(classification_report(y_test, pred_spss))\nprint(\"ROC: \" +  str(roc_spss))"
        }, 
        {
            "execution_count": 292, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "def evaluate_it(alg):\n    alg.fit(X_train_res_maptrsfm, y_train_res)\n    pred = alg.predict(X_test_maptrsfm)\n    roc = roc_auc_score(y_test, pred)\n    print(\"*****Confusion Matrix *****\")\n    print(confusion_matrix(y_test, pred))\n    print(\"*****Classification Report*****\")\n    print(classification_report(y_test, pred))\n    print(\"ROC: \" +  str(roc))\n\n    "
        }, 
        {
            "source": "### Plot Feature Importance", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 272, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 272, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "<matplotlib.axes._subplots.AxesSubplot at 0x7fbeeebc21d0>"
                    }, 
                    "output_type": "execute_result"
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/wAAAJOCAYAAAAK1AwxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n", 
                        "text/plain": "<matplotlib.figure.Figure at 0x7fbeeec4d7b8>"
                    }, 
                    "metadata": {}
                }
            ], 
            "source": "fig, axs = plt.subplots(nrows= 1, figsize=(13, 10))\nfeat_imp = pd.Series(xgb_model_spss._Booster.get_fscore()).sort_values()\nX_train_dummy_names  =  mapper1.fit(X_train_df).transformed_names_\n\nx=[]\nfor i in range(0, len(X_train_dummy_names)):\n    x.append( \"f\"+ str(i))\n\nfeat_imp_reindex = feat_imp.rename(lambda y: dict(zip(x, X_train_dummy_names))[y])\nfeat_imp_reindex.plot(kind='barh', title='Feature Importances')"
        }, 
        {
            "source": "## Hyperparameter Tuning\n\nLets try tuning hyperpafameters and see if we could further boost model performance. \n\n1. Start with the default values from SPSS Modeler  \n2. Fix learning rate and search for the optimum number of trees by training with early_stopping_rounds configured\n3. Use RandomizedSearchCV to search on hyper parameters.\n\nYou can try brute-force grid search but it's gonna take a long time. That's why we want to be a little bit conservative on how to search for optimal parameters. Even small improvement would be good enough to give you the idea.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### Set learning_rate and n_estimators", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 280, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "xgb_model_1 = XGBClassifier(\n    tree_method= \"auto\",\n    n_estimators = 1000, # start with a large value\n    max_depth = 6,\n    min_child_weight = 1.0,\n    max_delta_step = 0.0,\n    objective = \"binary:logistic\",\n    seed = 6924827,\n    subsample = 1.0,\n    learning_rate = .1, # lower it\n    gamma = 0.0,\n    colsample_bytree = 1.0,\n    colsample_bylevel = 1.0,\n    reg_lambda = 1.0,\n    reg_alpha = 0.0,\n    scale_pos_weight = 1.0)"
        }, 
        {
            "execution_count": 281, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "[0]\tTrain-auc:0.699632\tTest-auc:0.65423\nMultiple eval metrics have been passed: 'Test-auc' will be used for early stopping.\n\nWill train until Test-auc hasn't improved in 10 rounds.\n[1]\tTrain-auc:0.707122\tTest-auc:0.648356\n[2]\tTrain-auc:0.715468\tTest-auc:0.652281\n[3]\tTrain-auc:0.71773\tTest-auc:0.655368\n[4]\tTrain-auc:0.720271\tTest-auc:0.656795\n[5]\tTrain-auc:0.722457\tTest-auc:0.65844\n[6]\tTrain-auc:0.725514\tTest-auc:0.657708\n[7]\tTrain-auc:0.72751\tTest-auc:0.661627\n[8]\tTrain-auc:0.729337\tTest-auc:0.661908\n[9]\tTrain-auc:0.731244\tTest-auc:0.663043\n"
                }
            ], 
            "source": "xgtrain = xgb.DMatrix(X_train_res_maptrsfm, label=y_train_res)\nxgb_param = xgb_model_1.get_xgb_params()\nxgb_param['eval_metric'] = 'auc'\ndtest = xgb.DMatrix(mapper1.fit_transform(X_test), label = y_test)\n\nmodel = xgb.train(\n    xgb_param,\n    xgtrain,\n    evals=[(xgtrain, \"Train\"),(dtest, \"Test\")],\n    early_stopping_rounds=10\n)"
        }, 
        {
            "execution_count": 290, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Best AUC: 0.66 with 10 rounds\n"
                }
            ], 
            "source": "print(\"Best AUC: {:.2f} with {} rounds\".format(\n                 model.best_score,\n                 model.best_iteration+1))"
        }, 
        {
            "execution_count": 291, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "xgb_model_1 = XGBClassifier(\n    tree_method= \"auto\",\n    n_estimators = 10, # reset to\n    max_depth = 6,\n    min_child_weight = 1.0,\n    max_delta_step = 0.0,\n    objective = \"binary:logistic\",\n    seed = 6924827,\n    subsample = 1.0,\n    learning_rate = .1, # fixed\n    gamma = 0.0,\n    colsample_bytree = 1.0,\n    colsample_bylevel = 1.0,\n    reg_lambda = 1.0,\n    reg_alpha = 0.0,\n    scale_pos_weight = 1.0)"
        }, 
        {
            "execution_count": 293, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "*****Confusion Matrix *****\n[[6952 3456]\n [ 255  344]]\n*****Classification Report*****\n             precision    recall  f1-score   support\n\n          0       0.96      0.67      0.79     10408\n          1       0.09      0.57      0.16       599\n\navg / total       0.92      0.66      0.75     11007\n\nROC: 0.6211191083268424\n"
                }
            ], 
            "source": "evaluate_it(xgb_model_1)"
        }, 
        {
            "source": "By lowering the learning rate, roc increased. Move forward with learning_rate = .1, and n_estimators = 10", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### Use RandomizedSearchCV to search on hyperparameters.\n\nYou can add more parameters and more options if you want to be very thorough. But here my goal is to get a quick output.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }, 
        {
            "source": "### Build Pipeline", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 182, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "mapper1 = DataFrameMapper(\n    [(['Dollar_Amount'], None),\n     (['Last3hourTransactions'], None),\n     (['Hours_Since_Last_Transaction'], None),\n     ('Transaction_Type', LabelBinarizer()), # for binary, only one variable generated\n     ('Store_Type', LabelBinarizer()),\n     ('Cardholder_Region', LabelBinarizer()),\n     ('Country', LabelBinarizer())\n     ])"
        }, 
        {
            "execution_count": 183, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# build pipeline\npipeline = Pipeline([('mapper', mapper1), ('classifier', XGBClassifier(tree_method= \"auto\",\n    n_estimators = ,\n    max_depth = 6,\n    min_child_weight = 1.0,\n    max_delta_step = 0.0,\n    objective = \"binary:logistic\",\n    seed = 6924827,\n    subsample = 1.0,\n    learning_rate = .2,\n    gamma = 0.0,\n    colsample_bytree = 1.0,\n    colsample_bylevel = 1.0,\n    reg_lambda = 1.0,\n    reg_alpha = 0.0,\n    scale_pos_weight = 1.0))])"
        }, 
        {
            "execution_count": 187, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "pipeline = Pipeline([('mapper', mapper1), ('classifier', XGBClassifier(\n    tree_method= \"auto\",\n    n_estimators = 10, \n    max_delta_step = 0.0,\n    objective = \"binary:logistic\",\n    seed = 6924827,\n    learning_rate = .01, # fixed\n    colsample_bylevel = 1.0,\n    reg_lambda = 1.0,\n    reg_alpha = 0.0,\n    scale_pos_weight = 1.0,\n    gamma = 0.5,\n    colsample_bytree = 0.6,\n    subsample = .8,\n    min_child_weight = 1.0,\n    max_depth = 6))])"
        }, 
        {
            "execution_count": 188, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 188, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "Pipeline(memory=None,\n     steps=[('mapper', DataFrameMapper(default=False, df_out=False,\n        features=[(['Dollar_Amount'], None), (['Last3hourTransactions'], None), (['Hours_Since_Last_Transaction'], None), ('Transaction_Type', LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False)), ('Store_Type', LabelBinarizer(...da=1.0, scale_pos_weight=1.0, seed=6924827, silent=True,\n       subsample=0.8, tree_method='auto'))])"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "# fit ppl\npipeline.fit(X_train_df, y_train_res)"
        }, 
        {
            "source": "### Model Evaluation", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 189, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "/gpfs/fs01/user/s34f-24c5585e483e16-c0ce2641d0ef/.local/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n  if diff:\n"
                }
            ], 
            "source": "pred_classifier = pipeline.predict(X_test)"
        }, 
        {
            "execution_count": 190, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "*****Confusion Matrix *****\n[[7002 3406]\n [ 255  344]]\n*****Classification Report*****\n             precision    recall  f1-score   support\n\n          0       0.96      0.67      0.79     10408\n          1       0.09      0.57      0.16       599\n\navg / total       0.92      0.67      0.76     11007\n\nROC: 0.6235211067895634\n"
                }
            ], 
            "source": "roc = roc_auc_score(y_test, pred_classifier)\nprint(\"*****Confusion Matrix *****\")\nprint(confusion_matrix(y_test, pred_classifier))\nprint(\"*****Classification Report*****\")\nprint(classification_report(y_test, pred_classifier))\nprint(\"ROC: \" +  str(roc))"
        }, 
        {
            "source": "## Hyperparameter Tuning\n\nLets try tuning hyperpafameters and see if we could further boost model performance. In order to make it clear, we will get rid of pipleline for now. Here is the strategy:\n\n1. Start with the default values from SPSS Modeler  \n2. Fix learning rate at .1 and search for the optimum number of trees by training with early_stopping_rounds configured\n3. Use RandomizedSearchCV to search on hyper parameters.\n\nYou can try brute-force grid search but it's gonna take a long time. That's why we want to be a little bit conservative on how to search for optimal parameters. Even small improvement would be good enough to give you the idea.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 124, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "xgb_model = XGBClassifier(\n    tree_method= \"auto\",\n    n_estimators = 1000, # start with a large value\n    max_depth = 6,\n    min_child_weight = 1.0,\n    max_delta_step = 0.0,\n    objective = \"binary:logistic\",\n    seed = 6924827,\n    subsample = 1.0,\n    learning_rate = .1, # fixed\n    gamma = 0.0,\n    colsample_bytree = 1.0,\n    colsample_bylevel = 1.0,\n    reg_lambda = 1.0,\n    reg_alpha = 0.0,\n    scale_pos_weight = 1.0)"
        }, 
        {
            "execution_count": 211, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "X_train_res = mapper1.fit_transform(X_train_df)"
        }, 
        {
            "execution_count": 229, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "[0]\tTrain-auc:0.696744\tTest-auc:0.654399\nMultiple eval metrics have been passed: 'Test-auc' will be used for early stopping.\n\nWill train until Test-auc hasn't improved in 10 rounds.\n[1]\tTrain-auc:0.709144\tTest-auc:0.657518\n[2]\tTrain-auc:0.713448\tTest-auc:0.658664\n[3]\tTrain-auc:0.713423\tTest-auc:0.660792\n[4]\tTrain-auc:0.721051\tTest-auc:0.665305\n[5]\tTrain-auc:0.720711\tTest-auc:0.664873\n[6]\tTrain-auc:0.722232\tTest-auc:0.665524\n[7]\tTrain-auc:0.724308\tTest-auc:0.666046\n[8]\tTrain-auc:0.723701\tTest-auc:0.666994\n[9]\tTrain-auc:0.72525\tTest-auc:0.666754\n"
                }
            ], 
            "source": "xgtrain = xgb.DMatrix(X_train_res, label=y_train_res)\nxgb_param = xgb_model.get_xgb_params()\nxgb_param['eval_metric'] = 'auc'\ndtest = xgb.DMatrix(mapper1.fit_transform(X_test), label = y_test)\n\nmodel = xgb.train(\n    xgb_param,\n    xgtrain,\n    evals=[(xgtrain, \"Train\"),(dtest, \"Test\")],\n    early_stopping_rounds=10\n)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "{'gamma': 2, 'colsample_bytree': 1.0, 'subsample': 0.8, 'min_child_weight': 1, 'max_depth': 6}"
        }, 
        {
            "execution_count": 230, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Best AUC: 0.67 with 9 rounds\n"
                }
            ], 
            "source": "print(\"Best AUC: {:.2f} with {} rounds\".format(\n                 model.best_score,\n                 model.best_iteration+1))"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "{'gamma': 0, 'colsample_bytree': 0.8, 'subsample': 0.8, 'min_child_weight': 1, 'max_depth': 6}"
        }, 
        {
            "execution_count": 223, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 223, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,\n       colsample_bytree=0.8, gamma=0.0, learning_rate=0.1,\n       max_delta_step=0.0, max_depth=6, min_child_weight=1.0, missing=None,\n       n_estimators=6, n_jobs=1, nthread=None, objective='binary:logistic',\n       random_state=0, reg_alpha=0.0, reg_lambda=1.0, scale_pos_weight=1.0,\n       seed=6924827, silent=True, subsample=0.8, tree_method='auto')"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "xgb_model = XGBClassifier(\n    tree_method= \"auto\",\n    n_estimators = 6, # reset n_estimators = 6\n    max_depth = 6,\n    min_child_weight = 1.0,\n    max_delta_step = 0.0,\n    objective = \"binary:logistic\",\n    seed = 6924827,\n    subsample = .8,\n    learning_rate = .1, # fixed\n    gamma = 0.0,\n    colsample_bytree = .8,\n    colsample_bylevel = 1.0,\n    reg_lambda = 1.0,\n    reg_alpha = 0.0,\n    scale_pos_weight = 1.0)\n\n\nxgb_model.fit(X_train_res, y_train_res)"
        }, 
        {
            "execution_count": 224, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "/gpfs/fs01/user/s34f-24c5585e483e16-c0ce2641d0ef/.local/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n  if diff:\n"
                }
            ], 
            "source": "pred_6rounds = xgb_model.predict(mapper1.fit_transform(X_test))"
        }, 
        {
            "execution_count": 225, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 225, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "0.6275747498713586"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "roc_auc_score(y_test, pred_6rounds)"
        }, 
        {
            "source": "### 3. Use RandomizedSearchCV to search on hyperparameters.\n\nYou can add more parameters and more options if you want to be very thorough. But here my goal is to get a quick output.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 219, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "params = {\n        'min_child_weight': [1, 5, 10],\n        'gamma': [0, 0.5, 1, 2],\n        'subsample': [0.6, 0.8, 1.0],\n        'colsample_bytree': [0.6, 0.8, 1.0],\n        'max_depth': [3, 4, 5, 6]\n        }"
        }, 
        {
            "execution_count": 220, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "folds = 3\n\n# increase param_comb if you want to run through more candiates\nparam_comb = 50\n\nskf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n\nrandom_search = RandomizedSearchCV(xgb_model, param_distributions=params, n_iter=param_comb, scoring='roc_auc', cv=skf.split(X_train_res, y_train_res), verbose=3, random_state=1001 )"
        }, 
        {
            "execution_count": 221, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n[CV] gamma=0.5, colsample_bytree=0.8, subsample=0.6, min_child_weight=10, max_depth=3 \n[CV]  gamma=0.5, colsample_bytree=0.8, subsample=0.6, min_child_weight=10, max_depth=3, score=0.6805438693062402, total=   0.5s\n[CV] gamma=0.5, colsample_bytree=0.8, subsample=0.6, min_child_weight=10, max_depth=3 \n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s remaining:    0.0s\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "[CV]  gamma=0.5, colsample_bytree=0.8, subsample=0.6, min_child_weight=10, max_depth=3, score=0.681443617447793, total=   0.5s\n[CV] gamma=0.5, colsample_bytree=0.8, subsample=0.6, min_child_weight=10, max_depth=3 \n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.1s remaining:    0.0s\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "[CV]  gamma=0.5, colsample_bytree=0.8, subsample=0.6, min_child_weight=10, max_depth=3, score=0.6884851474569439, total=   0.5s\n[CV] gamma=2, colsample_bytree=1.0, subsample=0.8, min_child_weight=10, max_depth=5 \n[CV]  gamma=2, colsample_bytree=1.0, subsample=0.8, min_child_weight=10, max_depth=5, score=0.7033261516019359, total=   0.8s\n[CV] gamma=2, colsample_bytree=1.0, subsample=0.8, min_child_weight=10, max_depth=5 \n[CV]  gamma=2, colsample_bytree=1.0, subsample=0.8, min_child_weight=10, max_depth=5, score=0.6994220266976487, total=   0.8s\n[CV] gamma=2, colsample_bytree=1.0, subsample=0.8, min_child_weight=10, max_depth=5 \n[CV]  gamma=2, colsample_bytree=1.0, subsample=0.8, min_child_weight=10, max_depth=5, score=0.7055599700162016, total=   0.8s\n[CV] gamma=0, colsample_bytree=1.0, subsample=1.0, min_child_weight=5, max_depth=6 \n[CV]  gamma=0, colsample_bytree=1.0, subsample=1.0, min_child_weight=5, max_depth=6, score=0.7151560272736843, total=   0.8s\n[CV] gamma=0, colsample_bytree=1.0, subsample=1.0, min_child_weight=5, max_depth=6 \n[CV]  gamma=0, colsample_bytree=1.0, subsample=1.0, min_child_weight=5, max_depth=6, score=0.7141820801083318, total=   0.8s\n[CV] gamma=0, colsample_bytree=1.0, subsample=1.0, min_child_weight=5, max_depth=6 \n[CV]  gamma=0, colsample_bytree=1.0, subsample=1.0, min_child_weight=5, max_depth=6, score=0.7189368145566298, total=   0.8s\n[CV] gamma=2, colsample_bytree=1.0, subsample=0.8, min_child_weight=1, max_depth=6 \n[CV]  gamma=2, colsample_bytree=1.0, subsample=0.8, min_child_weight=1, max_depth=6, score=0.7185472961767162, total=   0.9s\n[CV] gamma=2, colsample_bytree=1.0, subsample=0.8, min_child_weight=1, max_depth=6 \n[CV]  gamma=2, colsample_bytree=1.0, subsample=0.8, min_child_weight=1, max_depth=6, score=0.715694499450723, total=   0.9s\n[CV] gamma=2, colsample_bytree=1.0, subsample=0.8, min_child_weight=1, max_depth=6 \n[CV]  gamma=2, colsample_bytree=1.0, subsample=0.8, min_child_weight=1, max_depth=6, score=0.7204557529701944, total=   0.9s\n[CV] gamma=1, colsample_bytree=0.6, subsample=1.0, min_child_weight=1, max_depth=5 \n[CV]  gamma=1, colsample_bytree=0.6, subsample=1.0, min_child_weight=1, max_depth=5, score=0.7090656457749513, total=   0.5s\n[CV] gamma=1, colsample_bytree=0.6, subsample=1.0, min_child_weight=1, max_depth=5 \n[CV]  gamma=1, colsample_bytree=0.6, subsample=1.0, min_child_weight=1, max_depth=5, score=0.7069597376374216, total=   0.5s\n[CV] gamma=1, colsample_bytree=0.6, subsample=1.0, min_child_weight=1, max_depth=5 \n[CV]  gamma=1, colsample_bytree=0.6, subsample=1.0, min_child_weight=1, max_depth=5, score=0.7106782654642707, total=   0.5s\n[CV] gamma=0, colsample_bytree=0.6, subsample=0.6, min_child_weight=5, max_depth=3 \n[CV]  gamma=0, colsample_bytree=0.6, subsample=0.6, min_child_weight=5, max_depth=3, score=0.6843412127552695, total=   0.4s\n[CV] gamma=0, colsample_bytree=0.6, subsample=0.6, min_child_weight=5, max_depth=3 \n[CV]  gamma=0, colsample_bytree=0.6, subsample=0.6, min_child_weight=5, max_depth=3, score=0.6828875296754737, total=   0.4s\n[CV] gamma=0, colsample_bytree=0.6, subsample=0.6, min_child_weight=5, max_depth=3 \n[CV]  gamma=0, colsample_bytree=0.6, subsample=0.6, min_child_weight=5, max_depth=3, score=0.6897947233924498, total=   0.4s\n[CV] gamma=0, colsample_bytree=1.0, subsample=1.0, min_child_weight=5, max_depth=5 \n[CV]  gamma=0, colsample_bytree=1.0, subsample=1.0, min_child_weight=5, max_depth=5, score=0.700376191764791, total=   0.7s\n[CV] gamma=0, colsample_bytree=1.0, subsample=1.0, min_child_weight=5, max_depth=5 \n[CV]  gamma=0, colsample_bytree=1.0, subsample=1.0, min_child_weight=5, max_depth=5, score=0.7008884790921135, total=   0.7s\n[CV] gamma=0, colsample_bytree=1.0, subsample=1.0, min_child_weight=5, max_depth=5 \n[CV]  gamma=0, colsample_bytree=1.0, subsample=1.0, min_child_weight=5, max_depth=5, score=0.7052720271401807, total=   0.7s\n[CV] gamma=0.5, colsample_bytree=1.0, subsample=0.8, min_child_weight=10, max_depth=6 \n[CV]  gamma=0.5, colsample_bytree=1.0, subsample=0.8, min_child_weight=10, max_depth=6, score=0.7135476648842152, total=   0.9s\n[CV] gamma=0.5, colsample_bytree=1.0, subsample=0.8, min_child_weight=10, max_depth=6 \n[CV]  gamma=0.5, colsample_bytree=1.0, subsample=0.8, min_child_weight=10, max_depth=6, score=0.712048066554123, total=   0.9s\n[CV] gamma=0.5, colsample_bytree=1.0, subsample=0.8, min_child_weight=10, max_depth=6 \n[CV]  gamma=0.5, colsample_bytree=1.0, subsample=0.8, min_child_weight=10, max_depth=6, score=0.7169161247927855, total=   0.9s\n[CV] gamma=1, colsample_bytree=1.0, subsample=0.8, min_child_weight=5, max_depth=4 \n[CV]  gamma=1, colsample_bytree=1.0, subsample=0.8, min_child_weight=5, max_depth=4, score=0.6902821725933243, total=   0.7s\n[CV] gamma=1, colsample_bytree=1.0, subsample=0.8, min_child_weight=5, max_depth=4 \n[CV]  gamma=1, colsample_bytree=1.0, subsample=0.8, min_child_weight=5, max_depth=4, score=0.6885568236363883, total=   0.6s\n[CV] gamma=1, colsample_bytree=1.0, subsample=0.8, min_child_weight=5, max_depth=4 \n[CV]  gamma=1, colsample_bytree=1.0, subsample=0.8, min_child_weight=5, max_depth=4, score=0.694508978596271, total=   0.6s\n[CV] gamma=2, colsample_bytree=0.8, subsample=0.6, min_child_weight=5, max_depth=4 \n[CV]  gamma=2, colsample_bytree=0.8, subsample=0.6, min_child_weight=5, max_depth=4, score=0.6918141181306567, total=   0.6s\n[CV] gamma=2, colsample_bytree=0.8, subsample=0.6, min_child_weight=5, max_depth=4 \n[CV]  gamma=2, colsample_bytree=0.8, subsample=0.6, min_child_weight=5, max_depth=4, score=0.6934999933620243, total=   0.6s\n[CV] gamma=2, colsample_bytree=0.8, subsample=0.6, min_child_weight=5, max_depth=4 \n[CV]  gamma=2, colsample_bytree=0.8, subsample=0.6, min_child_weight=5, max_depth=4, score=0.6970034306133845, total=   0.6s\n[CV] gamma=1, colsample_bytree=0.8, subsample=0.6, min_child_weight=1, max_depth=6 \n[CV]  gamma=1, colsample_bytree=0.8, subsample=0.6, min_child_weight=1, max_depth=6, score=0.7215141844028827, total=   0.9s\n[CV] gamma=1, colsample_bytree=0.8, subsample=0.6, min_child_weight=1, max_depth=6 \n[CV]  gamma=1, colsample_bytree=0.8, subsample=0.6, min_child_weight=1, max_depth=6, score=0.718429014583612, total=   0.9s\n[CV] gamma=1, colsample_bytree=0.8, subsample=0.6, min_child_weight=1, max_depth=6 \n[CV]  gamma=1, colsample_bytree=0.8, subsample=0.6, min_child_weight=1, max_depth=6, score=0.7236775027587923, total=   0.9s\n[CV] gamma=1, colsample_bytree=1.0, subsample=0.8, min_child_weight=5, max_depth=3 \n[CV]  gamma=1, colsample_bytree=1.0, subsample=0.8, min_child_weight=5, max_depth=3, score=0.6780836824784489, total=   0.5s\n[CV] gamma=1, colsample_bytree=1.0, subsample=0.8, min_child_weight=5, max_depth=3 \n[CV]  gamma=1, colsample_bytree=1.0, subsample=0.8, min_child_weight=5, max_depth=3, score=0.676991489908333, total=   0.5s\n[CV] gamma=1, colsample_bytree=1.0, subsample=0.8, min_child_weight=5, max_depth=3 \n[CV]  gamma=1, colsample_bytree=1.0, subsample=0.8, min_child_weight=5, max_depth=3, score=0.683383702851451, total=   0.5s\n[CV] gamma=2, colsample_bytree=0.8, subsample=0.6, min_child_weight=1, max_depth=3 \n[CV]  gamma=2, colsample_bytree=0.8, subsample=0.6, min_child_weight=1, max_depth=3, score=0.6805857366320888, total=   0.5s\n[CV] gamma=2, colsample_bytree=0.8, subsample=0.6, min_child_weight=1, max_depth=3 \n[CV]  gamma=2, colsample_bytree=0.8, subsample=0.6, min_child_weight=1, max_depth=3, score=0.6813803679820777, total=   0.5s\n[CV] gamma=2, colsample_bytree=0.8, subsample=0.6, min_child_weight=1, max_depth=3 \n[CV]  gamma=2, colsample_bytree=0.8, subsample=0.6, min_child_weight=1, max_depth=3, score=0.6885159178864619, total=   0.5s\n[CV] gamma=1, colsample_bytree=1.0, subsample=0.6, min_child_weight=5, max_depth=5 \n[CV]  gamma=1, colsample_bytree=1.0, subsample=0.6, min_child_weight=5, max_depth=5, score=0.7023994431462136, total=   0.9s\n[CV] gamma=1, colsample_bytree=1.0, subsample=0.6, min_child_weight=5, max_depth=5 \n[CV]  gamma=1, colsample_bytree=1.0, subsample=0.6, min_child_weight=5, max_depth=5, score=0.7019439689296415, total=   0.9s\n[CV] gamma=1, colsample_bytree=1.0, subsample=0.6, min_child_weight=5, max_depth=5 \n[CV]  gamma=1, colsample_bytree=1.0, subsample=0.6, min_child_weight=5, max_depth=5, score=0.7054252744254967, total=   0.9s\n[CV] gamma=0, colsample_bytree=0.6, subsample=1.0, min_child_weight=5, max_depth=5 \n[CV]  gamma=0, colsample_bytree=0.6, subsample=1.0, min_child_weight=5, max_depth=5, score=0.7087237848554728, total=   0.5s\n[CV] gamma=0, colsample_bytree=0.6, subsample=1.0, min_child_weight=5, max_depth=5 \n[CV]  gamma=0, colsample_bytree=0.6, subsample=1.0, min_child_weight=5, max_depth=5, score=0.7064633783499755, total=   0.5s\n[CV] gamma=0, colsample_bytree=0.6, subsample=1.0, min_child_weight=5, max_depth=5 \n[CV]  gamma=0, colsample_bytree=0.6, subsample=1.0, min_child_weight=5, max_depth=5, score=0.7098713352480481, total=   0.5s\n[CV] gamma=2, colsample_bytree=1.0, subsample=0.6, min_child_weight=1, max_depth=5 \n[CV]  gamma=2, colsample_bytree=1.0, subsample=0.6, min_child_weight=1, max_depth=5, score=0.7036660997090953, total=   0.9s\n[CV] gamma=2, colsample_bytree=1.0, subsample=0.6, min_child_weight=1, max_depth=5 \n[CV]  gamma=2, colsample_bytree=1.0, subsample=0.6, min_child_weight=1, max_depth=5, score=0.70298143955815, total=   0.9s\n[CV] gamma=2, colsample_bytree=1.0, subsample=0.6, min_child_weight=1, max_depth=5 \n[CV]  gamma=2, colsample_bytree=1.0, subsample=0.6, min_child_weight=1, max_depth=5, score=0.7067684848392357, total=   0.9s\n[CV] gamma=2, colsample_bytree=1.0, subsample=0.8, min_child_weight=5, max_depth=3 \n[CV]  gamma=2, colsample_bytree=1.0, subsample=0.8, min_child_weight=5, max_depth=3, score=0.6780836824784489, total=   0.5s\n[CV] gamma=2, colsample_bytree=1.0, subsample=0.8, min_child_weight=5, max_depth=3 \n[CV]  gamma=2, colsample_bytree=1.0, subsample=0.8, min_child_weight=5, max_depth=3, score=0.676991489908333, total=   0.5s\n[CV] gamma=2, colsample_bytree=1.0, subsample=0.8, min_child_weight=5, max_depth=3 \n[CV]  gamma=2, colsample_bytree=1.0, subsample=0.8, min_child_weight=5, max_depth=3, score=0.683383702851451, total=   0.6s\n[CV] gamma=0, colsample_bytree=0.8, subsample=0.6, min_child_weight=1, max_depth=5 \n[CV]  gamma=0, colsample_bytree=0.8, subsample=0.6, min_child_weight=1, max_depth=5, score=0.7054049934451541, total=   0.8s\n[CV] gamma=0, colsample_bytree=0.8, subsample=0.6, min_child_weight=1, max_depth=5 \n[CV]  gamma=0, colsample_bytree=0.8, subsample=0.6, min_child_weight=1, max_depth=5, score=0.7046254836520099, total=   0.7s\n[CV] gamma=0, colsample_bytree=0.8, subsample=0.6, min_child_weight=1, max_depth=5 \n[CV]  gamma=0, colsample_bytree=0.8, subsample=0.6, min_child_weight=1, max_depth=5, score=0.7103120808097652, total=   0.7s\n[CV] gamma=0, colsample_bytree=0.8, subsample=1.0, min_child_weight=10, max_depth=4 \n[CV]  gamma=0, colsample_bytree=0.8, subsample=1.0, min_child_weight=10, max_depth=4, score=0.6923712376429223, total=   0.5s\n[CV] gamma=0, colsample_bytree=0.8, subsample=1.0, min_child_weight=10, max_depth=4 \n[CV]  gamma=0, colsample_bytree=0.8, subsample=1.0, min_child_weight=10, max_depth=4, score=0.6920139320564102, total=   0.5s\n[CV] gamma=0, colsample_bytree=0.8, subsample=1.0, min_child_weight=10, max_depth=4 \n[CV]  gamma=0, colsample_bytree=0.8, subsample=1.0, min_child_weight=10, max_depth=4, score=0.6955853672008232, total=   0.5s\n[CV] gamma=2, colsample_bytree=1.0, subsample=1.0, min_child_weight=1, max_depth=6 \n[CV]  gamma=2, colsample_bytree=1.0, subsample=1.0, min_child_weight=1, max_depth=6, score=0.7172517716571092, total=   0.8s\n[CV] gamma=2, colsample_bytree=1.0, subsample=1.0, min_child_weight=1, max_depth=6 \n[CV]  gamma=2, colsample_bytree=1.0, subsample=1.0, min_child_weight=1, max_depth=6, score=0.7181791883703658, total=   0.8s\n[CV] gamma=2, colsample_bytree=1.0, subsample=1.0, min_child_weight=1, max_depth=6 \n[CV]  gamma=2, colsample_bytree=1.0, subsample=1.0, min_child_weight=1, max_depth=6, score=0.720381667681181, total=   0.8s\n[CV] gamma=1, colsample_bytree=0.8, subsample=1.0, min_child_weight=5, max_depth=5 \n[CV]  gamma=1, colsample_bytree=0.8, subsample=1.0, min_child_weight=5, max_depth=5, score=0.707228337845089, total=   0.6s\n[CV] gamma=1, colsample_bytree=0.8, subsample=1.0, min_child_weight=5, max_depth=5 \n[CV]  gamma=1, colsample_bytree=0.8, subsample=1.0, min_child_weight=5, max_depth=5, score=0.7046472173357623, total=   0.6s\n[CV] gamma=1, colsample_bytree=0.8, subsample=1.0, min_child_weight=5, max_depth=5 \n[CV]  gamma=1, colsample_bytree=0.8, subsample=1.0, min_child_weight=5, max_depth=5, score=0.706613466910084, total=   0.6s\n[CV] gamma=0, colsample_bytree=1.0, subsample=0.6, min_child_weight=5, max_depth=4 \n[CV]  gamma=0, colsample_bytree=1.0, subsample=0.6, min_child_weight=5, max_depth=4, score=0.6898442859105596, total=   0.7s\n[CV] gamma=0, colsample_bytree=1.0, subsample=0.6, min_child_weight=5, max_depth=4 \n[CV]  gamma=0, colsample_bytree=1.0, subsample=0.6, min_child_weight=5, max_depth=4, score=0.6889718134387204, total=   0.7s\n[CV] gamma=0, colsample_bytree=1.0, subsample=0.6, min_child_weight=5, max_depth=4 \n[CV]  gamma=0, colsample_bytree=1.0, subsample=0.6, min_child_weight=5, max_depth=4, score=0.6935581144228199, total=   0.7s\n[CV] gamma=1, colsample_bytree=1.0, subsample=0.6, min_child_weight=5, max_depth=4 \n[CV]  gamma=1, colsample_bytree=1.0, subsample=0.6, min_child_weight=5, max_depth=4, score=0.6898425798887616, total=   0.7s\n[CV] gamma=1, colsample_bytree=1.0, subsample=0.6, min_child_weight=5, max_depth=4 \n[CV]  gamma=1, colsample_bytree=1.0, subsample=0.6, min_child_weight=5, max_depth=4, score=0.6889718134387204, total=   0.7s\n[CV] gamma=1, colsample_bytree=1.0, subsample=0.6, min_child_weight=5, max_depth=4 \n[CV]  gamma=1, colsample_bytree=1.0, subsample=0.6, min_child_weight=5, max_depth=4, score=0.6935581144228199, total=   0.7s\n[CV] gamma=2, colsample_bytree=0.8, subsample=0.8, min_child_weight=1, max_depth=4 \n[CV]  gamma=2, colsample_bytree=0.8, subsample=0.8, min_child_weight=1, max_depth=4, score=0.691978697536521, total=   0.5s\n[CV] gamma=2, colsample_bytree=0.8, subsample=0.8, min_child_weight=1, max_depth=4 \n[CV]  gamma=2, colsample_bytree=0.8, subsample=0.8, min_child_weight=1, max_depth=4, score=0.6930125674250832, total=   0.5s\n[CV] gamma=2, colsample_bytree=0.8, subsample=0.8, min_child_weight=1, max_depth=4 \n[CV]  gamma=2, colsample_bytree=0.8, subsample=0.8, min_child_weight=1, max_depth=4, score=0.6979967101075649, total=   0.5s\n[CV] gamma=2, colsample_bytree=1.0, subsample=0.8, min_child_weight=1, max_depth=5 \n[CV]  gamma=2, colsample_bytree=1.0, subsample=0.8, min_child_weight=1, max_depth=5, score=0.7042516580877553, total=   0.7s\n[CV] gamma=2, colsample_bytree=1.0, subsample=0.8, min_child_weight=1, max_depth=5 \n[CV]  gamma=2, colsample_bytree=1.0, subsample=0.8, min_child_weight=1, max_depth=5, score=0.7007581493662822, total=   0.7s\n[CV] gamma=2, colsample_bytree=1.0, subsample=0.8, min_child_weight=1, max_depth=5 \n[CV]  gamma=2, colsample_bytree=1.0, subsample=0.8, min_child_weight=1, max_depth=5, score=0.7053053695268029, total=   0.7s\n[CV] gamma=2, colsample_bytree=0.8, subsample=1.0, min_child_weight=10, max_depth=5 \n[CV]  gamma=2, colsample_bytree=0.8, subsample=1.0, min_child_weight=10, max_depth=5, score=0.7061896910954926, total=   0.6s\n[CV] gamma=2, colsample_bytree=0.8, subsample=1.0, min_child_weight=10, max_depth=5 \n[CV]  gamma=2, colsample_bytree=0.8, subsample=1.0, min_child_weight=10, max_depth=5, score=0.703070646404008, total=   0.6s\n[CV] gamma=2, colsample_bytree=0.8, subsample=1.0, min_child_weight=10, max_depth=5 \n[CV]  gamma=2, colsample_bytree=0.8, subsample=1.0, min_child_weight=10, max_depth=5, score=0.7057700226576238, total=   0.6s\n[CV] gamma=0.5, colsample_bytree=1.0, subsample=1.0, min_child_weight=1, max_depth=4 \n[CV]  gamma=0.5, colsample_bytree=1.0, subsample=1.0, min_child_weight=1, max_depth=4, score=0.6894814383380858, total=   0.6s\n[CV] gamma=0.5, colsample_bytree=1.0, subsample=1.0, min_child_weight=1, max_depth=4 \n[CV]  gamma=0.5, colsample_bytree=1.0, subsample=1.0, min_child_weight=1, max_depth=4, score=0.6871808188309072, total=   0.6s\n[CV] gamma=0.5, colsample_bytree=1.0, subsample=1.0, min_child_weight=1, max_depth=4 \n[CV]  gamma=0.5, colsample_bytree=1.0, subsample=1.0, min_child_weight=1, max_depth=4, score=0.6931743034612845, total=   0.6s\n[CV] gamma=1, colsample_bytree=1.0, subsample=1.0, min_child_weight=5, max_depth=5 \n[CV]  gamma=1, colsample_bytree=1.0, subsample=1.0, min_child_weight=5, max_depth=5, score=0.700376949135074, total=   0.7s\n[CV] gamma=1, colsample_bytree=1.0, subsample=1.0, min_child_weight=5, max_depth=5 \n[CV]  gamma=1, colsample_bytree=1.0, subsample=1.0, min_child_weight=5, max_depth=5, score=0.7008884790921135, total=   0.7s\n[CV] gamma=1, colsample_bytree=1.0, subsample=1.0, min_child_weight=5, max_depth=5 \n[CV]  gamma=1, colsample_bytree=1.0, subsample=1.0, min_child_weight=5, max_depth=5, score=0.7052720271401807, total=   0.7s\n[CV] gamma=1, colsample_bytree=0.6, subsample=0.6, min_child_weight=1, max_depth=5 \n[CV]  gamma=1, colsample_bytree=0.6, subsample=0.6, min_child_weight=1, max_depth=5, score=0.7056192491039146, total=   0.6s\n[CV] gamma=1, colsample_bytree=0.6, subsample=0.6, min_child_weight=1, max_depth=5 \n[CV]  gamma=1, colsample_bytree=0.6, subsample=0.6, min_child_weight=1, max_depth=5, score=0.7033510285016067, total=   0.6s\n[CV] gamma=1, colsample_bytree=0.6, subsample=0.6, min_child_weight=1, max_depth=5 \n[CV]  gamma=1, colsample_bytree=0.6, subsample=0.6, min_child_weight=1, max_depth=5, score=0.7113643628093369, total=   0.6s\n[CV] gamma=1, colsample_bytree=1.0, subsample=0.6, min_child_weight=1, max_depth=6 \n[CV]  gamma=1, colsample_bytree=1.0, subsample=0.6, min_child_weight=1, max_depth=6, score=0.7199238515619591, total=   1.0s\n[CV] gamma=1, colsample_bytree=1.0, subsample=0.6, min_child_weight=1, max_depth=6 \n[CV]  gamma=1, colsample_bytree=1.0, subsample=0.6, min_child_weight=1, max_depth=6, score=0.7175612440112431, total=   1.0s\n[CV] gamma=1, colsample_bytree=1.0, subsample=0.6, min_child_weight=1, max_depth=6 \n[CV]  gamma=1, colsample_bytree=1.0, subsample=0.6, min_child_weight=1, max_depth=6, score=0.7213149546603511, total=   1.0s\n[CV] gamma=2, colsample_bytree=1.0, subsample=0.6, min_child_weight=5, max_depth=6 \n[CV]  gamma=2, colsample_bytree=1.0, subsample=0.6, min_child_weight=5, max_depth=6, score=0.7161595041254294, total=   1.0s\n[CV] gamma=2, colsample_bytree=1.0, subsample=0.6, min_child_weight=5, max_depth=6 \n[CV]  gamma=2, colsample_bytree=1.0, subsample=0.6, min_child_weight=5, max_depth=6, score=0.7161539854034016, total=   1.0s\n[CV] gamma=2, colsample_bytree=1.0, subsample=0.6, min_child_weight=5, max_depth=6 \n[CV]  gamma=2, colsample_bytree=1.0, subsample=0.6, min_child_weight=5, max_depth=6, score=0.7182336983516894, total=   1.0s\n[CV] gamma=0.5, colsample_bytree=0.6, subsample=0.8, min_child_weight=1, max_depth=6 \n[CV]  gamma=0.5, colsample_bytree=0.6, subsample=0.8, min_child_weight=1, max_depth=6, score=0.7215796827155135, total=   0.6s\n[CV] gamma=0.5, colsample_bytree=0.6, subsample=0.8, min_child_weight=1, max_depth=6 \n[CV]  gamma=0.5, colsample_bytree=0.6, subsample=0.8, min_child_weight=1, max_depth=6, score=0.7176112046011056, total=   0.6s\n[CV] gamma=0.5, colsample_bytree=0.6, subsample=0.8, min_child_weight=1, max_depth=6 \n[CV]  gamma=0.5, colsample_bytree=0.6, subsample=0.8, min_child_weight=1, max_depth=6, score=0.726238435343511, total=   0.6s\n[CV] gamma=0, colsample_bytree=0.6, subsample=0.8, min_child_weight=1, max_depth=5 \n[CV]  gamma=0, colsample_bytree=0.6, subsample=0.8, min_child_weight=1, max_depth=5, score=0.7068539901347688, total=   0.5s\n[CV] gamma=0, colsample_bytree=0.6, subsample=0.8, min_child_weight=1, max_depth=5 \n[CV]  gamma=0, colsample_bytree=0.6, subsample=0.8, min_child_weight=1, max_depth=5, score=0.7059237119576783, total=   0.5s\n[CV] gamma=0, colsample_bytree=0.6, subsample=0.8, min_child_weight=1, max_depth=5 \n[CV]  gamma=0, colsample_bytree=0.6, subsample=0.8, min_child_weight=1, max_depth=5, score=0.7113779308523931, total=   0.5s\n[CV] gamma=0.5, colsample_bytree=0.8, subsample=0.8, min_child_weight=5, max_depth=3 \n[CV]  gamma=0.5, colsample_bytree=0.8, subsample=0.8, min_child_weight=5, max_depth=3, score=0.6838726099254983, total=   0.4s\n[CV] gamma=0.5, colsample_bytree=0.8, subsample=0.8, min_child_weight=5, max_depth=3 \n[CV]  gamma=0.5, colsample_bytree=0.8, subsample=0.8, min_child_weight=5, max_depth=3, score=0.6816986987251531, total=   0.4s\n[CV] gamma=0.5, colsample_bytree=0.8, subsample=0.8, min_child_weight=5, max_depth=3 \n[CV]  gamma=0.5, colsample_bytree=0.8, subsample=0.8, min_child_weight=5, max_depth=3, score=0.6870382574457614, total=   0.4s\n[CV] gamma=1, colsample_bytree=0.6, subsample=0.6, min_child_weight=5, max_depth=6 \n[CV]  gamma=1, colsample_bytree=0.6, subsample=0.6, min_child_weight=5, max_depth=6, score=0.7180875465661235, total=   0.7s\n[CV] gamma=1, colsample_bytree=0.6, subsample=0.6, min_child_weight=5, max_depth=6 \n[CV]  gamma=1, colsample_bytree=0.6, subsample=0.6, min_child_weight=5, max_depth=6, score=0.7146291663843977, total=   0.7s\n[CV] gamma=1, colsample_bytree=0.6, subsample=0.6, min_child_weight=5, max_depth=6 \n[CV]  gamma=1, colsample_bytree=0.6, subsample=0.6, min_child_weight=5, max_depth=6, score=0.7194355571048301, total=   0.7s\n[CV] gamma=1, colsample_bytree=0.8, subsample=0.6, min_child_weight=5, max_depth=6 \n[CV]  gamma=1, colsample_bytree=0.8, subsample=0.6, min_child_weight=5, max_depth=6, score=0.7198585212666267, total=   0.9s\n[CV] gamma=1, colsample_bytree=0.8, subsample=0.6, min_child_weight=5, max_depth=6 \n[CV]  gamma=1, colsample_bytree=0.8, subsample=0.6, min_child_weight=5, max_depth=6, score=0.7157815220717035, total=   0.8s\n[CV] gamma=1, colsample_bytree=0.8, subsample=0.6, min_child_weight=5, max_depth=6 \n[CV]  gamma=1, colsample_bytree=0.8, subsample=0.6, min_child_weight=5, max_depth=6, score=0.7221240432526361, total=   0.9s\n[CV] gamma=0.5, colsample_bytree=0.6, subsample=1.0, min_child_weight=1, max_depth=5 \n[CV]  gamma=0.5, colsample_bytree=0.6, subsample=1.0, min_child_weight=1, max_depth=5, score=0.7090848411050586, total=   0.5s\n[CV] gamma=0.5, colsample_bytree=0.6, subsample=1.0, min_child_weight=1, max_depth=5 \n[CV]  gamma=0.5, colsample_bytree=0.6, subsample=1.0, min_child_weight=1, max_depth=5, score=0.7069597376374216, total=   0.5s\n[CV] gamma=0.5, colsample_bytree=0.6, subsample=1.0, min_child_weight=1, max_depth=5 \n[CV]  gamma=0.5, colsample_bytree=0.6, subsample=1.0, min_child_weight=1, max_depth=5, score=0.7106969593273651, total=   0.5s\n[CV] gamma=1, colsample_bytree=0.8, subsample=0.6, min_child_weight=10, max_depth=4 \n[CV]  gamma=1, colsample_bytree=0.8, subsample=0.6, min_child_weight=10, max_depth=4, score=0.6920094731358021, total=   0.6s\n[CV] gamma=1, colsample_bytree=0.8, subsample=0.6, min_child_weight=10, max_depth=4 \n[CV]  gamma=1, colsample_bytree=0.8, subsample=0.6, min_child_weight=10, max_depth=4, score=0.6936927505612501, total=   0.6s\n[CV] gamma=1, colsample_bytree=0.8, subsample=0.6, min_child_weight=10, max_depth=4 \n[CV]  gamma=1, colsample_bytree=0.8, subsample=0.6, min_child_weight=10, max_depth=4, score=0.6967425436921488, total=   0.6s\n[CV] gamma=2, colsample_bytree=0.8, subsample=0.6, min_child_weight=10, max_depth=5 \n[CV]  gamma=2, colsample_bytree=0.8, subsample=0.6, min_child_weight=10, max_depth=5, score=0.7040855536017987, total=   0.7s\n[CV] gamma=2, colsample_bytree=0.8, subsample=0.6, min_child_weight=10, max_depth=5 \n[CV]  gamma=2, colsample_bytree=0.8, subsample=0.6, min_child_weight=10, max_depth=5, score=0.7027924562859315, total=   0.8s\n[CV] gamma=2, colsample_bytree=0.8, subsample=0.6, min_child_weight=10, max_depth=5 \n[CV]  gamma=2, colsample_bytree=0.8, subsample=0.6, min_child_weight=10, max_depth=5, score=0.7086334665105647, total=   0.7s\n[CV] gamma=2, colsample_bytree=0.6, subsample=0.8, min_child_weight=10, max_depth=5 \n[CV]  gamma=2, colsample_bytree=0.6, subsample=0.8, min_child_weight=10, max_depth=5, score=0.7043884655266552, total=   0.6s\n[CV] gamma=2, colsample_bytree=0.6, subsample=0.8, min_child_weight=10, max_depth=5 \n[CV]  gamma=2, colsample_bytree=0.6, subsample=0.8, min_child_weight=10, max_depth=5, score=0.7044838114661043, total=   0.6s\n[CV] gamma=2, colsample_bytree=0.6, subsample=0.8, min_child_weight=10, max_depth=5 \n[CV]  gamma=2, colsample_bytree=0.6, subsample=0.8, min_child_weight=10, max_depth=5, score=0.709288643502985, total=   0.6s\n[CV] gamma=0, colsample_bytree=0.8, subsample=1.0, min_child_weight=5, max_depth=6 \n[CV]  gamma=0, colsample_bytree=0.8, subsample=1.0, min_child_weight=5, max_depth=6, score=0.7229857393534521, total=   0.7s\n[CV] gamma=0, colsample_bytree=0.8, subsample=1.0, min_child_weight=5, max_depth=6 \n[CV]  gamma=0, colsample_bytree=0.8, subsample=1.0, min_child_weight=5, max_depth=6, score=0.7150743476027891, total=   0.7s\n[CV] gamma=0, colsample_bytree=0.8, subsample=1.0, min_child_weight=5, max_depth=6 \n[CV]  gamma=0, colsample_bytree=0.8, subsample=1.0, min_child_weight=5, max_depth=6, score=0.7226471948369536, total=   0.7s\n[CV] gamma=1, colsample_bytree=1.0, subsample=0.8, min_child_weight=5, max_depth=6 \n[CV]  gamma=1, colsample_bytree=1.0, subsample=0.8, min_child_weight=5, max_depth=6, score=0.7155734158460598, total=   0.9s\n[CV] gamma=1, colsample_bytree=1.0, subsample=0.8, min_child_weight=5, max_depth=6 \n[CV]  gamma=1, colsample_bytree=1.0, subsample=0.8, min_child_weight=5, max_depth=6, score=0.7138998911785561, total=   0.9s\n[CV] gamma=1, colsample_bytree=1.0, subsample=0.8, min_child_weight=5, max_depth=6 \n[CV]  gamma=1, colsample_bytree=1.0, subsample=0.8, min_child_weight=5, max_depth=6, score=0.719068702966013, total=   0.9s\n[CV] gamma=1, colsample_bytree=0.8, subsample=0.8, min_child_weight=10, max_depth=6 \n[CV]  gamma=1, colsample_bytree=0.8, subsample=0.8, min_child_weight=10, max_depth=6, score=0.7197509333283373, total=   0.8s\n[CV] gamma=1, colsample_bytree=0.8, subsample=0.8, min_child_weight=10, max_depth=6 \n[CV]  gamma=1, colsample_bytree=0.8, subsample=0.8, min_child_weight=10, max_depth=6, score=0.7131711226094913, total=   0.8s\n[CV] gamma=1, colsample_bytree=0.8, subsample=0.8, min_child_weight=10, max_depth=6 \n[CV]  gamma=1, colsample_bytree=0.8, subsample=0.8, min_child_weight=10, max_depth=6, score=0.7204333808207086, total=   0.8s\n[CV] gamma=0, colsample_bytree=0.6, subsample=0.8, min_child_weight=10, max_depth=6 \n[CV]  gamma=0, colsample_bytree=0.6, subsample=0.8, min_child_weight=10, max_depth=6, score=0.7159005765443799, total=   0.6s\n[CV] gamma=0, colsample_bytree=0.6, subsample=0.8, min_child_weight=10, max_depth=6 \n[CV]  gamma=0, colsample_bytree=0.6, subsample=0.8, min_child_weight=10, max_depth=6, score=0.7129404710473005, total=   0.6s\n[CV] gamma=0, colsample_bytree=0.6, subsample=0.8, min_child_weight=10, max_depth=6 \n[CV]  gamma=0, colsample_bytree=0.6, subsample=0.8, min_child_weight=10, max_depth=6, score=0.7209865299549717, total=   0.6s\n[CV] gamma=0, colsample_bytree=0.8, subsample=0.8, min_child_weight=1, max_depth=6 \n[CV]  gamma=0, colsample_bytree=0.8, subsample=0.8, min_child_weight=1, max_depth=6, score=0.7231128121285784, total=   0.8s\n[CV] gamma=0, colsample_bytree=0.8, subsample=0.8, min_child_weight=1, max_depth=6 \n[CV]  gamma=0, colsample_bytree=0.8, subsample=0.8, min_child_weight=1, max_depth=6, score=0.7184139188755823, total=   0.8s\n[CV] gamma=0, colsample_bytree=0.8, subsample=0.8, min_child_weight=1, max_depth=6 \n[CV]  gamma=0, colsample_bytree=0.8, subsample=0.8, min_child_weight=1, max_depth=6, score=0.7257724458289483, total=   0.8s\n[CV] gamma=1, colsample_bytree=0.6, subsample=0.6, min_child_weight=5, max_depth=3 \n[CV]  gamma=1, colsample_bytree=0.6, subsample=0.6, min_child_weight=5, max_depth=3, score=0.6843412127552695, total=   0.4s\n[CV] gamma=1, colsample_bytree=0.6, subsample=0.6, min_child_weight=5, max_depth=3 \n[CV]  gamma=1, colsample_bytree=0.6, subsample=0.6, min_child_weight=5, max_depth=3, score=0.6828875296754737, total=   0.5s\n[CV] gamma=1, colsample_bytree=0.6, subsample=0.6, min_child_weight=5, max_depth=3 \n[CV]  gamma=1, colsample_bytree=0.6, subsample=0.6, min_child_weight=5, max_depth=3, score=0.6897947233924498, total=   0.4s\n[CV] gamma=1, colsample_bytree=0.8, subsample=0.8, min_child_weight=1, max_depth=4 \n[CV]  gamma=1, colsample_bytree=0.8, subsample=0.8, min_child_weight=1, max_depth=4, score=0.691978697536521, total=   0.6s\n[CV] gamma=1, colsample_bytree=0.8, subsample=0.8, min_child_weight=1, max_depth=4 \n[CV]  gamma=1, colsample_bytree=0.8, subsample=0.8, min_child_weight=1, max_depth=4, score=0.6930125674250832, total=   0.6s\n[CV] gamma=1, colsample_bytree=0.8, subsample=0.8, min_child_weight=1, max_depth=4 \n[CV]  gamma=1, colsample_bytree=0.8, subsample=0.8, min_child_weight=1, max_depth=4, score=0.6979967101075649, total=   0.6s\n[CV] gamma=0.5, colsample_bytree=0.8, subsample=0.6, min_child_weight=5, max_depth=3 \n[CV]  gamma=0.5, colsample_bytree=0.8, subsample=0.6, min_child_weight=5, max_depth=3, score=0.6805857366320888, total=   0.5s\n[CV] gamma=0.5, colsample_bytree=0.8, subsample=0.6, min_child_weight=5, max_depth=3 \n[CV]  gamma=0.5, colsample_bytree=0.8, subsample=0.6, min_child_weight=5, max_depth=3, score=0.681490328841595, total=   0.5s\n[CV] gamma=0.5, colsample_bytree=0.8, subsample=0.6, min_child_weight=5, max_depth=3 \n[CV]  gamma=0.5, colsample_bytree=0.8, subsample=0.6, min_child_weight=5, max_depth=3, score=0.6885159178864619, total=   0.5s\n[CV] gamma=0.5, colsample_bytree=1.0, subsample=0.6, min_child_weight=5, max_depth=5 \n[CV]  gamma=0.5, colsample_bytree=1.0, subsample=0.6, min_child_weight=5, max_depth=5, score=0.702376329135734, total=   0.9s\n[CV] gamma=0.5, colsample_bytree=1.0, subsample=0.6, min_child_weight=5, max_depth=5 \n[CV]  gamma=0.5, colsample_bytree=1.0, subsample=0.6, min_child_weight=5, max_depth=5, score=0.7019439689296415, total=   0.9s\n[CV] gamma=0.5, colsample_bytree=1.0, subsample=0.6, min_child_weight=5, max_depth=5 \n[CV]  gamma=0.5, colsample_bytree=1.0, subsample=0.6, min_child_weight=5, max_depth=5, score=0.7054252744254967, total=   0.9s\n[CV] gamma=0, colsample_bytree=1.0, subsample=0.8, min_child_weight=1, max_depth=5 \n[CV]  gamma=0, colsample_bytree=1.0, subsample=0.8, min_child_weight=1, max_depth=5, score=0.7042668985491495, total=   0.8s\n[CV] gamma=0, colsample_bytree=1.0, subsample=0.8, min_child_weight=1, max_depth=5 \n[CV]  gamma=0, colsample_bytree=1.0, subsample=0.8, min_child_weight=1, max_depth=5, score=0.7007687525502441, total=   0.8s\n[CV] gamma=0, colsample_bytree=1.0, subsample=0.8, min_child_weight=1, max_depth=5 \n[CV]  gamma=0, colsample_bytree=1.0, subsample=0.8, min_child_weight=1, max_depth=5, score=0.7053053695268029, total=   0.8s\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "[Parallel(n_jobs=1)]: Done 150 out of 150 | elapsed:  1.8min finished\n"
                }, 
                {
                    "execution_count": 221, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "RandomizedSearchCV(cv=<generator object _BaseKFold.split at 0x7fbeee814360>,\n          error_score='raise',\n          estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,\n       colsample_bytree=1.0, gamma=0.0, learning_rate=0.1,\n       max_delta_step=0.0, max_depth=6, min_child_weight=1.0, missing=None,\n       n_estimators=6, n_jobs=1, nthread=None, objective='binary:logistic',\n       random_state=0, reg_alpha=0.0, reg_lambda=1.0, scale_pos_weight=1.0,\n       seed=6924827, silent=True, subsample=1.0, tree_method='auto'),\n          fit_params=None, iid=True, n_iter=50, n_jobs=1,\n          param_distributions={'colsample_bytree': [0.6, 0.8, 1.0], 'gamma': [0, 0.5, 1, 2], 'min_child_weight': [1, 5, 10], 'subsample': [0.6, 0.8, 1.0], 'max_depth': [3, 4, 5, 6]},\n          pre_dispatch='2*n_jobs', random_state=1001, refit=True,\n          return_train_score='warn', scoring='roc_auc', verbose=3)"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "random_search.fit(X_train_res, y_train_res)"
        }, 
        {
            "execution_count": 222, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "\n Best hyperparameters:\n{'gamma': 0, 'colsample_bytree': 0.8, 'subsample': 0.8, 'min_child_weight': 1, 'max_depth': 6}\n"
                }
            ], 
            "source": "print('\\n Best hyperparameters:')\nprint(random_search.best_params_)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": " Best hyperparameters:\n{'gamma': 0.5, 'colsample_bytree': 0.6, 'subsample': 0.8, 'min_child_weight': 1, 'max_depth': 6}"
        }, 
        {
            "source": "### 4. Reset hyperparameters", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Here I recalibrated learning_rate and n_estimators through looping from Step 2 between Step 3. And here is the best model with ROC = .63, the highest we've got so far.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 235, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 235, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,\n       colsample_bytree=0.8, gamma=0.0, learning_rate=0.01,\n       max_delta_step=0.0, max_depth=6, min_child_weight=1.0, missing=None,\n       n_estimators=6, n_jobs=1, nthread=None, objective='binary:logistic',\n       random_state=0, reg_alpha=0.0, reg_lambda=1.0, scale_pos_weight=1.0,\n       seed=6924827, silent=True, subsample=0.8, tree_method='auto')"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "xgb_model = XGBClassifier(\n    tree_method= \"auto\",\n    n_estimators = 6, \n    max_delta_step = 0.0,\n    objective = \"binary:logistic\",\n    seed = 6924827,\n    learning_rate = .01, # fixed\n    colsample_bylevel = 1.0,\n    reg_lambda = 1.0,\n    reg_alpha = 0.0,\n    scale_pos_weight = 1.0,\n    gamma = 0.0,\n    colsample_bytree = 0.8,\n    subsample = .8,\n    min_child_weight = 1.0,\n    max_depth = 6)\n\n\nxgb_model.fit(X_train_res, y_train_res)"
        }, 
        {
            "execution_count": 236, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "*****Confusion Matrix *****\n[[6832 3576]\n [ 239  360]]\n*****Classification Report*****\n             precision    recall  f1-score   support\n\n          0       0.97      0.66      0.78     10408\n          1       0.09      0.60      0.16       599\n\navg / total       0.92      0.65      0.75     11007\n\nROC: 0.6287099046707362\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "/gpfs/fs01/user/s34f-24c5585e483e16-c0ce2641d0ef/.local/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n  if diff:\n"
                }
            ], 
            "source": "pred_classifier_tuned = xgb_model.predict(mapper1.fit_transform(X_test))\nroc_tuned = roc_auc_score(y_test, pred_classifier_tuned)\nprint(\"*****Confusion Matrix *****\")\nprint(confusion_matrix(y_test, pred_classifier_tuned))\nprint(\"*****Classification Report*****\")\nprint(classification_report(y_test, pred_classifier_tuned))\nprint(\"ROC: \" +  str(roc_tuned))"
        }, 
        {
            "source": "## Model Deployment using DSX Machine Learning", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 26, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "Using TensorFlow backend.\n"
                }
            ], 
            "source": "from dsx_ml.ml import save"
        }, 
        {
            "execution_count": 154, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 154, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "{'path': '/user-home/1042/DSX_Projects/DTE FSS Fraud Detection/models/local_xgb/1',\n 'scoring_endpoint': 'https://dsxl-api.ibm-private-cloud.svc.cluster.local/v3/project/score/Python35/scikit-learn-0.19/DTE%20FSS%20Fraud%20Detection/local_xgb/1'}"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "model_name = \"local_xgb\"\nsave(name = model_name,\n     model = pipeline,\n     algorithm_type = 'Classification',\n     x_test = X_test,\n     y_test = pd.DataFrame(y_test))"
        }, 
        {
            "source": "### Online Scoring", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 158, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "json_payload =[{\n    'Dollar_Amount': 1000,\n    'Transaction_Type':' keyed',\n    'Store_Type': 'Retail - Furniture',\n    'Cardholder_Region': 'SW',\n    'Country': 'Asia',\n    'Last3hourTransactions': 100,\n    'Hours_Since_Last_Transaction': 12}]"
        }, 
        {
            "execution_count": 159, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Prediction: [0]\nProbabilities: [[0.6900818347930908, 0.3099181652069092]]\n"
                }
            ], 
            "source": "import requests, json, os\nfrom pprint import pprint\n\nonline_path='https://dsxl-api.ibm-private-cloud.svc.cluster.local/v3/project/score/Python35/scikit-learn-0.19/DTE%20FSS%20Fraud%20Detection/local_xgb/1'\nheader_online = {'Content-Type': 'application/json', 'Authorization':os.environ['DSX_TOKEN']}\n\nresponse_scoring = requests.post(online_path, json=json_payload, headers=header_online)\n\nresponse_dict = json.loads(response_scoring.content.decode('utf-8'))\n\npred=response_dict['object']['output']['predictions']\nprob=response_dict['object']['output']['probabilities']\nprint(\"Prediction: %s\" % pred)\nprint(\"Probabilities: %s\" % prob)"
        }, 
        {
            "source": "### Batch Scoring", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "** Preparing data for Batch Scoring **", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 161, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 161, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dollar_Amount</th>\n      <th>Transaction_Type</th>\n      <th>Store_Type</th>\n      <th>Cardholder_Region</th>\n      <th>Country</th>\n      <th>Last3hourTransactions</th>\n      <th>Hours_Since_Last_Transaction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>171.72</td>\n      <td>keyed</td>\n      <td>Utilities</td>\n      <td>NW</td>\n      <td>USA</td>\n      <td>1</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>152.98</td>\n      <td>keyed</td>\n      <td>Retail - Books</td>\n      <td>NE</td>\n      <td>USA</td>\n      <td>2</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>126.30</td>\n      <td>swiped</td>\n      <td>Retail - Home Improvement</td>\n      <td>S</td>\n      <td>USA</td>\n      <td>1</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>126.30</td>\n      <td>swiped</td>\n      <td>Retail - Home Improvement</td>\n      <td>S</td>\n      <td>USA</td>\n      <td>2</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>181.16</td>\n      <td>keyed</td>\n      <td>Retail - Pharmacy</td>\n      <td>N</td>\n      <td>USA</td>\n      <td>2</td>\n      <td>23</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "   Dollar_Amount Transaction_Type                 Store_Type  \\\n0         171.72            keyed                  Utilities   \n1         152.98            keyed             Retail - Books   \n2         126.30           swiped  Retail - Home Improvement   \n3         126.30           swiped  Retail - Home Improvement   \n4         181.16            keyed          Retail - Pharmacy   \n\n  Cardholder_Region Country  Last3hourTransactions  \\\n0                NW     USA                      1   \n1                NE     USA                      2   \n2                 S     USA                      1   \n3                 S     USA                      2   \n4                 N     USA                      2   \n\n   Hours_Since_Last_Transaction  \n0                            15  \n1                            21  \n2                            18  \n3                            14  \n4                            23  "
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "df_data_2 = pd.read_csv(os.environ['DSX_PROJECT_DIR']+'/datasets/Current_Transactions_v6.csv')\ndf_data_2 = df_data_2[['Dollar_Amount', \n                       'Transaction_Type',\n                       'Store_Type', \n                       'Cardholder_Region', \n                       'Country',\n                       'Last3hourTransactions',\n                       'Hours_Since_Last_Transaction'\n                      ]]\ndf_data_2.head()"
        }, 
        {
            "source": "** Batch Scoring **\n\nNote: Modified the auto-generated script to make it work within notebook for batch scoring.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 163, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Done! The results have been saved as yhat.csv\n"
                }
            ], 
            "source": "import pandas as pd\nfrom sklearn import model_selection\nfrom sklearn.externals import joblib\nimport pickle\nimport sys, os\nimport json\nsys.path.insert(0, '/user-home/.scripts/common-helpers')\nimport published_model_util\n\n# name your input and output data\ntest_csv = \"Current_Transactions_v6_test2.csv\" # dont have to \nsave_csv = \"yhat.csv\"\nargs={'source': '/datasets/'+ test_csv, 'execution_type': 'DSX', 'target': '/datasets/'+ save_csv}\n#input_data = os.getenv(\"DSX_PROJECT_DIR\")+args.get(\"source\")\noutput_data = os.getenv(\"DSX_PROJECT_DIR\")+\"/datasets/\"+save_csv\nmodel_name = 'local_xgb'\nmodel_path = os.getenv(\"DSX_PROJECT_DIR\")+\"/models/\"+model_name+\"/1/model\"\nproject_name = 'DTE FSS Fraud Detection'\nis_published = 'false'\n\ndef scoring(model_path, input_data, output_data):\n    published_path = ''\n    # load model\n    if is_published == 'true':\n        copy_result = json.loads(published_model_util.copy_model(project_name, model_name))\n        if(copy_result['code'] == 200):\n            model_path = copy_result['path'] + '/model'\n            published_path = copy_result['path']\n        else:\n            raise Exception('Unable to score published model: ' + copy_result['description'])\n\n   # load the input data\n    dataframe = input_data\n\n    # load the model from disk \n    loaded_model = joblib.load(open(model_path, 'rb'))\n    \n    #predictions\n    scoring_result = loaded_model.predict(dataframe)\n\n    # feel free to write any code\n    #print(scoring_result)\n    scoring_output = pd.concat([dataframe.reset_index(drop=True), pd.DataFrame({'prediction':scoring_result})], 1)\n    # save to csv\n    scoring_output.to_csv(output_data)\n\n    if (len(published_path) > 0):\n        published_model_util.delete_temp_model()\n    \n    print(\"Done! The results have been saved as \" + save_csv)\n    \n    return scoring_output\n\n# invoke scoring: pay attention to input_data\nbatch_result = scoring(model_path,df_data_2, output_data)"
        }, 
        {
            "source": "Here is the result returned by batch scoring.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 165, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 165, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dollar_Amount</th>\n      <th>Transaction_Type</th>\n      <th>Store_Type</th>\n      <th>Cardholder_Region</th>\n      <th>Country</th>\n      <th>Last3hourTransactions</th>\n      <th>Hours_Since_Last_Transaction</th>\n      <th>prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>171.72</td>\n      <td>keyed</td>\n      <td>Utilities</td>\n      <td>NW</td>\n      <td>USA</td>\n      <td>1</td>\n      <td>15</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>152.98</td>\n      <td>keyed</td>\n      <td>Retail - Books</td>\n      <td>NE</td>\n      <td>USA</td>\n      <td>2</td>\n      <td>21</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>126.30</td>\n      <td>swiped</td>\n      <td>Retail - Home Improvement</td>\n      <td>S</td>\n      <td>USA</td>\n      <td>1</td>\n      <td>18</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>126.30</td>\n      <td>swiped</td>\n      <td>Retail - Home Improvement</td>\n      <td>S</td>\n      <td>USA</td>\n      <td>2</td>\n      <td>14</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>181.16</td>\n      <td>keyed</td>\n      <td>Retail - Pharmacy</td>\n      <td>N</td>\n      <td>USA</td>\n      <td>2</td>\n      <td>23</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "   Dollar_Amount Transaction_Type                 Store_Type  \\\n0         171.72            keyed                  Utilities   \n1         152.98            keyed             Retail - Books   \n2         126.30           swiped  Retail - Home Improvement   \n3         126.30           swiped  Retail - Home Improvement   \n4         181.16            keyed          Retail - Pharmacy   \n\n  Cardholder_Region Country  Last3hourTransactions  \\\n0                NW     USA                      1   \n1                NE     USA                      2   \n2                 S     USA                      1   \n3                 S     USA                      2   \n4                 N     USA                      2   \n\n   Hours_Since_Last_Transaction  prediction  \n0                            15           0  \n1                            21           0  \n2                            18           0  \n3                            14           0  \n4                            23           0  "
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "batch_result.head()"
        }, 
        {
            "execution_count": 175, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "display_data", 
                    "data": {
                        "text/html": "<!--\n  ~ Copyright (c) 2015 IBM Corporation and others.\n  ~\n  ~ Licensed under the Apache License, Version 2.0 (the \"License\");\n  ~ You may not use this file except in compliance with the License.\n  ~ You may obtain a copy of the License at\n  ~\n  ~     http://www.apache.org/licenses/LICENSE-2.0\n  ~\n  ~ Unless required by applicable law or agreed to in writing, software\n  ~ distributed under the License is distributed on an \"AS IS\" BASIS,\n  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n  ~ See the License for the specific language governing permissions and\n  ~ limitations under the License.\n  -->\n\n\n<link rel=\"stylesheet\" type=\"text/css\" href=\"/dsx-jupyter-py35/ibmdsxuser-1042/1519748209230/nbextensions/brunel_ext/brunel.2.3.css\">\n<link rel=\"stylesheet\" type=\"text/css\" href=\"/dsx-jupyter-py35/ibmdsxuser-1042/1519748209230/nbextensions/brunel_ext/sumoselect.css\">\n\n<style>\n    \n</style>\n\n<div id=\"controlsid7dd41988-20c0-11e8-8fba-3e8a7b75bb25\" class=\"brunel\"/>\n<svg id=\"visid7dd41636-20c0-11e8-8fba-3e8a7b75bb25\" width=\"500\" height=\"400\"></svg>", 
                        "text/plain": "<IPython.core.display.HTML object>"
                    }, 
                    "metadata": {}
                }, 
                {
                    "execution_count": 175, 
                    "metadata": {}, 
                    "data": {
                        "application/javascript": "/*\n * Copyright (c) 2015 IBM Corporation and others.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * You may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nrequire.config({\n    waitSeconds: 60,\n    paths: {\n        'd3': '//cdnjs.cloudflare.com/ajax/libs/d3/4.2.1/d3.min',\n        'topojson': '//cdnjs.cloudflare.com/ajax/libs/topojson/1.6.20/topojson.min',\n        'brunel' : '/dsx-jupyter-py35/ibmdsxuser-1042/1519748209230/nbextensions/brunel_ext/brunel.2.3.min',\n        'brunelControls' : '/dsx-jupyter-py35/ibmdsxuser-1042/1519748209230/nbextensions/brunel_ext/brunel.controls.2.3.min'\n    },\n    shim: {\n       'brunel' : {\n            exports: 'BrunelD3',\n            deps: ['d3', 'topojson'],\n            init: function() {\n               return {\n                 BrunelD3 : BrunelD3,\n                 BrunelData : BrunelData\n              }\n            }\n        },\n       'brunelControls' : {\n            exports: 'BrunelEventHandlers',\n            init: function() {\n               return {\n                 BrunelEventHandlers: BrunelEventHandlers,\n                 BrunelJQueryControlFactory: BrunelJQueryControlFactory\n              }\n            }\n        }\n\n    }\n\n});\n\nrequire([\"d3\"], function(d3) {\n    require([\"brunel\", \"brunelControls\"], function(brunel, brunelControls) {\n        function  BrunelVis(visId) {\n  \"use strict\";                                                                       // strict mode\n  var datasets = [],                                      // array of datasets for the original data\n      pre = function(d, i) { return d },                         // default pre-process does nothing\n      post = function(d, i) { return d },                       // default post-process does nothing\n      transitionTime = 200,                                        // transition time for animations\n      charts = [],                                                       // the charts in the system\n      vis = d3.select('#' + visId).attr('class', 'brunel');                     // the SVG container\n\n  BrunelD3.addDefinitions(vis);                                   // ensure standard symbols present\n\n  // Define chart #1 in the visualization //////////////////////////////////////////////////////////\n\n  charts[0] = function(parentNode, filterRows) {\n    var geom = BrunelD3.geometry(parentNode || vis.node(), 0, 0, 1, 1, 5, 42, 37, 76),\n      elements = [];                                              // array of elements in this chart\n\n    // Define groups for the chart parts ///////////////////////////////////////////////////////////\n\n    var chart =  vis.append('g').attr('class', 'chart1')\n      .attr('transform','translate(' + geom.chart_left + ',' + geom.chart_top + ')');\n    var overlay = chart.append('g').attr('class', 'element').attr('class', 'overlay');\n    var zoom = d3.zoom().scaleExtent([1/3,3]);\n    var zoomNode = overlay.append('rect').attr('class', 'overlay')\n      .attr('x', geom.inner_left).attr('y', geom.inner_top)\n      .attr('width', geom.inner_rawWidth).attr('height', geom.inner_rawHeight)\n      .style('cursor', 'move').call(zoom)\n      .node();\n    zoomNode.__zoom = d3.zoomIdentity;\n    chart.append('rect').attr('class', 'background').attr('width', geom.chart_right-geom.chart_left).attr('height', geom.chart_bottom-geom.chart_top);\n    var interior = chart.append('g').attr('class', 'interior zoomNone')\n      .attr('transform','translate(' + geom.inner_left + ',' + geom.inner_top + ')')\n      .attr('clip-path', 'url(#clip_visid7dd41636-20c0-11e8-8fba-3e8a7b75bb25_chart1_inner)');\n    interior.append('rect').attr('class', 'inner').attr('width', geom.inner_width).attr('height', geom.inner_height);\n    var gridGroup = interior.append('g').attr('class', 'grid');\n    var axes = chart.append('g').attr('class', 'axis')\n      .attr('transform','translate(' + geom.inner_left + ',' + geom.inner_top + ')');\n    var legends = chart.append('g').attr('class', 'legend')\n      .attr('transform','translate(' + (geom.chart_right-geom.chart_left - 3) + ',' + 0 + ')');\n    vis.append('clipPath').attr('id', 'clip_visid7dd41636-20c0-11e8-8fba-3e8a7b75bb25_chart1_inner').append('rect')\n      .attr('x', 0).attr('y', 0)\n      .attr('width', geom.inner_rawWidth+1).attr('height', geom.inner_rawHeight+1);\n\n    // Scales //////////////////////////////////////////////////////////////////////////////////////\n\n    var scale_x = d3.scaleLinear().domain([-0.2, 1.2000001])\n      .range([0, geom.inner_width]);\n    var scale_inner = d3.scaleLinear().domain([0,1])\n      .range([-0.5, 0.5]);\n    var scale_y = d3.scaleLinear().domain([0, 35000.003])\n      .range([geom.inner_height, 0]);\n    var base_scales = [scale_x, scale_y];                           // untransformed original scales\n\n    // Axes ////////////////////////////////////////////////////////////////////////////////////////\n\n    axes.append('g').attr('class', 'x axis')\n      .attr('transform','translate(0,' + geom.inner_rawHeight + ')')\n      .attr('clip-path', 'url(#clip_visid7dd41636-20c0-11e8-8fba-3e8a7b75bb25_chart1_haxis)');\n    vis.append('clipPath').attr('id', 'clip_visid7dd41636-20c0-11e8-8fba-3e8a7b75bb25_chart1_haxis').append('polyline')\n      .attr('points', '-1,-1000, -1,-1 -5,5, -1000,5, -100,1000, 10000,1000 10000,-1000');\n    axes.select('g.axis.x').append('text').attr('class', 'title').text('Prediction').style('text-anchor', 'middle')\n      .attr('x',geom.inner_rawWidth/2)\n      .attr('y', geom.inner_bottom - 2.0).attr('dy','-0.27em');\n    axes.append('g').attr('class', 'y axis')\n      .attr('clip-path', 'url(#clip_visid7dd41636-20c0-11e8-8fba-3e8a7b75bb25_chart1_vaxis)');\n    vis.append('clipPath').attr('id', 'clip_visid7dd41636-20c0-11e8-8fba-3e8a7b75bb25_chart1_vaxis').append('polyline')\n      .attr('points', '-1000,-10000, 10000,-10000, 10000,' + (geom.inner_rawHeight+1) + ', -1,' + (geom.inner_rawHeight+1) + ', -1,' + (geom.inner_rawHeight+5) + ', -1000,' + (geom.inner_rawHeight+5) );\n\n    var axis_bottom = d3.axisBottom(scale_x).ticks(Math.min(10, Math.round(geom.inner_width / 33.0)));\n    var axis_left = d3.axisLeft(scale_y).ticks(Math.min(10, Math.round(geom.inner_width / 20)));\n\n    function buildAxes(time) {\n      var axis_x = axes.select('g.axis.x');\n      BrunelD3.transition(axis_x, time).call(axis_bottom.scale(scale_x));\n      var axis_y = axes.select('g.axis.y');\n      BrunelD3.transition(axis_y, time).call(axis_left.scale(scale_y));\n    }\n    zoom.on('zoom', function(t, time) {\n        t = t ||BrunelD3.restrictZoom(d3.event.transform, geom, this);\n        scale_x = t.rescaleX(base_scales[0]);\n        scale_y = t.rescaleY(base_scales[1]);\n        zoomNode.__zoom = t;\n        interior.attr('class', 'interior ' + BrunelD3.zoomLabel(t.k));;\n        build(time || -1);\n    });\n\n    // Define element #1 ///////////////////////////////////////////////////////////////////////////\n\n    elements[0] = function() {\n      var original, processed,                           // data sets passed in and then transformed\n        element, data,                                 // brunel element information and brunel data\n        selection, merged;                                      // d3 selection and merged selection\n      var elementGroup = interior.append('g').attr('class', 'element1'),\n        main = elementGroup.append('g').attr('class', 'main'),\n        labels = BrunelD3.undoTransform(elementGroup.append('g').attr('class', 'labels').attr('aria-hidden', 'true'), elementGroup);\n\n      function makeData() {\n        original = datasets[0];\n        if (filterRows) original = original.retainRows(filterRows);\n        processed = pre(original, 0)\n          .summarize('#count=#count:sum; prediction=prediction:base');\n        processed = post(processed, 0);\n        var f0 = processed.field('prediction'),\n          f1 = processed.field('#count'),\n          f2 = processed.field('#row'),\n          f3 = processed.field('#selection');\n        var keyFunc = function(d) { return f2.value(d) };\n        data = {\n          prediction:   function(d) { return f0.value(d.row) },\n          $count:       function(d) { return f1.value(d.row) },\n          $row:         function(d) { return f2.value(d.row) },\n          $selection:   function(d) { return f3.value(d.row) },\n          prediction_f: function(d) { return f0.valueFormatted(d.row) },\n          $count_f:     function(d) { return f1.valueFormatted(d.row) },\n          $row_f:       function(d) { return f2.valueFormatted(d.row) },\n          $selection_f: function(d) { return f3.valueFormatted(d.row) },\n          _split:       function(d) { return f0.value(d.row) },\n          _key:         keyFunc,\n          _rows:        BrunelD3.makeRowsWithKeys(keyFunc, processed.rowCount())\n        };\n      }\n      // Aesthetic Functions\n      var scale_color = d3.scaleLinear().domain([0, 0.0555556, 0.1111111, 0.1666667, 0.2222222, 0.2777778, 0.3333333, 0.3888889, 0.4444444, 0.5, 0.5555556, 0.6111111, 0.6666667, 0.7222222, 0.7777778, 0.8333333, 0.8888889, 0.9444444, 1])\n        .interpolate(d3.interpolateHcl)\n        .range([ '#008000', '#108E10', '#239C23', '#39AA39', '#52B852', '#6EC76E', \n          '#8ED58E', '#B0E3B0', '#D6F1D6', '#ffffff', '#FFFFFF', '#FFE3E3', '#FFC6C6', \n          '#FFAAAA', '#FF8E8E', '#FF7171', '#FF5555', '#FF3939', '#FF1C1C']);\n      var color = function(d) { return scale_color(data.prediction(d)) };\n      legends._legend = legends._legend || { title: ['Prediction'], \n        ticks: [1, 0.8, 0.6, 0.4, 0.2, 0]};\n      legends._legend.color = scale_color;\n\n      // Build element from data ///////////////////////////////////////////////////////////////////\n\n      function build(transitionMillis) {\n        element = elements[0];\n        var w = Math.abs( scale_x(scale_x.domain()[0] + 1.0) - scale_x.range()[0] );\n        var x = function(d) { return scale_x(data.prediction(d))};\n        var h = Math.abs( scale_y(scale_y.domain()[0] + 11128.0) - scale_y.range()[0] );\n        var y1 = scale_y.range()[0];\n        var y2 = function(d) { return scale_y(data.$count(d))};\n\n        // Define selection entry operations\n        function initialState(selection) {\n          selection\n            .attr('class', 'element bar filled')\n        }\n\n        // Define selection update operations on merged data\n        function updateState(selection) {\n          selection\n            .each(function(d) {\n              var width = w, left = x(d) - width/2, \n              c = y1, d = y2(d), top = Math.min(c,d), height = Math.max(1e-6, Math.abs(c-d));\n              this.r = {x:left, y:top, w:width, h:height};\n            })\n            .attr('x', function(d) { return this.r.x })\n            .attr('y', function(d) { return this.r.y })\n            .attr('width', function(d) { return this.r.w })\n            .attr('height', function(d) { return this.r.h })\n            .filter(BrunelD3.hasData)                     // following only performed for data items\n            .style('fill', color);\n        }\n\n        // Define labeling for the selection\n        function label(selection, transitionMillis) {\n\n          var tooltipLabeling  = {\n            index: -1, method: 'box', location: ['center', 'top'], inside: true, align: 'middle', pad: 0, dy: 0.7,\n            fit: true, granularity: 0,\n            content: function(d) {\n              return d.row == null ? null : '<span class=\"title\">Prediction: </span>'\n\t\t\t+ '<span class=\"field\">' + data.prediction_f(d) + '</span>'\n\t\t\t+ '<br/>'\n\t\t\t+ '<span class=\"title\">Count: </span>'\n\t\t\t+ '<span class=\"field\">' + data.$count_f(d) + '</span>'\n            }\n          };\n          BrunelD3.addTooltip(selection, tooltipLabeling, geom);\n        }\n        // Create selections, set the initial state and transition updates\n        selection = main.selectAll('.element').data(data._rows, function(d) { return d.key });\n        var added = selection.enter().append('rect');\n        merged = selection.merge(added);\n        initialState(added);\n        selection.filter(BrunelD3.hasData)\n          .classed('selected', BrunelD3.isSelected(data))\n          .filter(BrunelD3.isSelected(data)).raise();\n        updateState(BrunelD3.transition(merged, transitionMillis));\n        label(merged, transitionMillis);\n\n        BrunelD3.transition(selection.exit(), transitionMillis/3)\n          .style('opacity', 0.5).each( function() {\n            this.remove(); BrunelD3.removeLabels(this); \n        });\n      }\n\n      return {\n        data:           function() { return processed },\n        original:       function() { return original },\n        internal:       function() { return data },\n        selection:      function() { return merged },\n        makeData:       makeData,\n        build:          build,\n        chart:          function() { return charts[0] },\n        group:          function() { return elementGroup },\n        fields: {\n          x:            ['prediction'],\n          y:            ['#count'],\n          key:          ['#row'],\n          color:        ['prediction']\n        }\n      };\n    }();\n\n    function build(time, noData) {\n      var first = elements[0].data() == null;\n      if (first) time = 0;                                           // no transition for first call\n      buildAxes(time);\n      if ((first || time > -1) && !noData) {\n        elements[0].makeData();\n        BrunelD3.addLegend(legends, legends._legend);\n      }\n      elements[0].build(time);\n    }\n\n    // Expose the following components of the chart\n    return {\n      elements : elements,\n      interior : interior,\n      scales: {x:scale_x, y:scale_y},\n      zoom: function(params, time) {\n          if (params) zoom.on('zoom').call(zoomNode, params, time);\n          return d3.zoomTransform(zoomNode);\n      },\n      build : build\n    };\n    }();\n\n  function setData(rowData, i) { datasets[i||0] = BrunelD3.makeData(rowData) }\n  function updateAll(time) { charts.forEach(function(x) {x.build(time || 0)}) }\n  function buildAll() {\n    for (var i=0;i<arguments.length;i++) setData(arguments[i], i);\n    updateAll(transitionTime);\n  }\n\n  return {\n    dataPreProcess:     function(f) { if (f) pre = f; return pre },\n    dataPostProcess:    function(f) { if (f) post = f; return post },\n    data:               function(d,i) { if (d) setData(d,i); return datasets[i||0] },\n    visId:              visId,\n    build:              buildAll,\n    rebuild:            updateAll,\n    charts:             charts\n  }\n}\n\n// Data Tables /////////////////////////////////////////////////////////////////////////////////////\n\nvar table1 = {\n   summarized: true,\n   names: ['prediction', '#count'], \n   options: ['numeric', 'numeric'], \n   rows: [[0, 33081], [1, 21953]]\n};\n\n// Call Code to Build the system ///////////////////////////////////////////////////////////////////\n\nvar v  = new BrunelVis('visid7dd41636-20c0-11e8-8fba-3e8a7b75bb25');\nv.build(table1);\n\n    });\n});", 
                        "text/plain": "<IPython.core.display.Javascript object>"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "%brunel data(\"batch_result\") bar x(prediction) y(#count) color(prediction: green-red) tooltip(#all)"
        }, 
        {
            "source": "## FQAs\n\nQ1. Does SMOTE help improve model performance?  \n    A: Yes. In this case, ROC on the same test set is .62 after SMOTE vs. .50 without SMOTE.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 193, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "***** Confusion Matrix *****\n[[10408     0]\n [  598     1]]\n***** ROC *****\n"
                }, 
                {
                    "execution_count": 193, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "0.5008347245409015"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "# do not do pipeline_beforesmote = pipeline\npipeline_beforesmote = Pipeline([('mapper', mapper1), ('classifier', XGBClassifier(tree_method= \"auto\",\n    n_estimators = 10,\n    max_depth = 6,\n    min_child_weight = 1.0,\n    max_delta_step = 0.0,\n    objective = \"binary:logistic\",\n    seed = 6924827,\n    subsample = 1.0,\n    learning_rate = .3,\n    gamma = 0.0,\n    colsample_bytree = 1.0,\n    colsample_bylevel = 1.0,\n    reg_lambda = 1.0,\n    reg_alpha = 0.0,\n    scale_pos_weight = 1.0))])\n\n\npipeline_beforesmote.fit(X_train, y_train)\n\npred_nosmote = pipeline_beforesmote.predict(X_test)\nprint(\"***** Confusion Matrix *****\")\nprint(confusion_matrix(np.array(y_test), pred_nosmote))\nprint(\"***** ROC *****\")\n\nroc_auc_score(y_test, pred_nosmote)"
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark 2.1", 
            "name": "python3-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }, 
        "anaconda-cloud": {}
    }, 
    "nbformat": 4
}