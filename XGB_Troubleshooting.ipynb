{"nbformat_minor": 1, "cells": [{"source": "<h1 id=\"tocheading\">XGB Troubleshooting</h1>\n<div id=\"toc\"></div>", "cell_type": "markdown", "metadata": {}}, {"source": "The purpose of this notebook is to show some comfusion we encoucotered when applying XGboost. We used same data for binary prediction and applied same technique(SMOTE) to handle imbalance. And tried to keep all the hyperparameters the same as well. But still the result is different.  \nAUC from SPSS output is .602 vs. .501 in the notebook. I have not checked xgb script in Modeler. Just wondering if  went wrong here.\n\nUnexpected inconsistency:\n1. AUC: SPSS(.602) vs. Notebook(.501 or .559)\n2. The built-in evaluation produced higher AUC values than roc_auc_score() on test set.\n\n** Any ideas?? **\n\nNote: \n1. Run the following cell to view the full Table of Contents:)\n2. I am experiencing trouble creating a new project in DSX right now. If you need to check the datasets(both original and processed data from Modeler), see [here](https://github.com/CatherineCao2016/Datasets). ", "cell_type": "markdown", "metadata": {}}, {"source": "%%javascript\n$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')\n", "cell_type": "code", "execution_count": 35, "outputs": [{"output_type": "display_data", "data": {"application/javascript": "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')", "text/plain": "<IPython.core.display.Javascript object>"}, "metadata": {}}], "metadata": {}}, {"source": "## Imports", "cell_type": "markdown", "metadata": {}}, {"source": "import numpy as np\nimport pandas as pd\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import roc_auc_score", "cell_type": "code", "execution_count": 1, "outputs": [], "metadata": {}}, {"source": "from io import StringIO\nimport requests\nimport json\nimport pandas as pd\n\n# @hidden_cell\n# This function accesses a file in your Object Storage. The definition contains your credentials.\n# You might want to remove those credentials before you share your notebook.\ndef get_object_storage_file_with_credentials_79f48b7520e04b748bcd13ec11f1f911(container, filename):\n    \"\"\"This functions returns a StringIO object containing\n    the file content from Bluemix Object Storage.\"\"\"\n\n    url1 = ''.join(['https://identity.open.softlayer.com', '/v3/auth/tokens'])\n    data = {'auth': {'identity': {'methods': ['password'],\n            'password': {'user': {'name': 'member_e477f3c5a924bd596600a5b14fe82d48597c4447','domain': {'id': '2028e4c0200e41428802c11a8d39a2a6'},\n            'password': 'ieP[&WmPw{96IBww'}}}}}\n    headers1 = {'Content-Type': 'application/json'}\n    resp1 = requests.post(url=url1, data=json.dumps(data), headers=headers1)\n    resp1_body = resp1.json()\n    for e1 in resp1_body['token']['catalog']:\n        if(e1['type']=='object-store'):\n            for e2 in e1['endpoints']:\n                        if(e2['interface']=='public'and e2['region']=='dallas'):\n                            url2 = ''.join([e2['url'],'/', container, '/', filename])\n    s_subject_token = resp1.headers['x-subject-token']\n    headers2 = {'X-Auth-Token': s_subject_token, 'accept': 'application/json'}\n    resp2 = requests.get(url=url2, headers=headers2)\n    return StringIO(resp2.text)\n\ndf_data_1 = pd.read_csv(get_object_storage_file_with_credentials_79f48b7520e04b748bcd13ec11f1f911('Defaultproject', 'History_Transactions_v4.csv')).drop(\"Hours Since Last Transaction\", 1)\ndf_data_1 = df_data_1[['Dollar_Amount', \n                       'Transaction_Type',\n                       'Store_Type', \n                       'Cardholder_Region', \n                       'Country',\n                       'Fraudulent',\n                       'Last3hourTransactions',\n                       'Hours_Since_Last_Transaction'\n                      ]]\ndf_data_1.head()", "cell_type": "code", "execution_count": 2, "outputs": [{"output_type": "execute_result", "data": {"text/plain": "   Dollar_Amount Transaction_Type                               Store_Type  \\\n0         188.56           swiped                           ATM Withdrawal   \n1         160.54            keyed                                  Grocery   \n2         153.24           swiped                        Retail - Pharmacy   \n3         148.66            keyed  Communications - telephone and wireless   \n4         174.03            keyed                               Spa/Beauty   \n\n  Cardholder_Region         Country Fraudulent  Last3hourTransactions  \\\n0                 E             USA          F                      4   \n1                NE       Australia          F                      3   \n2                SW  European Union          T                      2   \n3                NW             USA          F                      1   \n4                SW            Asia          F                      1   \n\n   Hours_Since_Last_Transaction  \n0                            21  \n1                            21  \n2                            21  \n3                            35  \n4                            25  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dollar_Amount</th>\n      <th>Transaction_Type</th>\n      <th>Store_Type</th>\n      <th>Cardholder_Region</th>\n      <th>Country</th>\n      <th>Fraudulent</th>\n      <th>Last3hourTransactions</th>\n      <th>Hours_Since_Last_Transaction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>188.56</td>\n      <td>swiped</td>\n      <td>ATM Withdrawal</td>\n      <td>E</td>\n      <td>USA</td>\n      <td>F</td>\n      <td>4</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>160.54</td>\n      <td>keyed</td>\n      <td>Grocery</td>\n      <td>NE</td>\n      <td>Australia</td>\n      <td>F</td>\n      <td>3</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>153.24</td>\n      <td>swiped</td>\n      <td>Retail - Pharmacy</td>\n      <td>SW</td>\n      <td>European Union</td>\n      <td>T</td>\n      <td>2</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>148.66</td>\n      <td>keyed</td>\n      <td>Communications - telephone and wireless</td>\n      <td>NW</td>\n      <td>USA</td>\n      <td>F</td>\n      <td>1</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>174.03</td>\n      <td>keyed</td>\n      <td>Spa/Beauty</td>\n      <td>SW</td>\n      <td>Asia</td>\n      <td>F</td>\n      <td>1</td>\n      <td>25</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "execution_count": 2, "metadata": {}}], "metadata": {}}, {"source": "## Split into Training and Test", "cell_type": "markdown", "metadata": {}}, {"source": "y = df_data_1['Fraudulent'].map(lambda l: 1 if l == 'T' else 0)\nX = df_data_1.drop(['Fraudulent'], axis=1)\n\nfrom sklearn.cross_validation import train_test_split \n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234567)\n\nprint(\"Number of training records: \" + str(len(X_train)))\nprint(\"Number of testing records : \" + str(len(X_test)))", "cell_type": "code", "execution_count": 4, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Number of training records: 44028\nNumber of testing records : 11007\n"}, {"output_type": "stream", "name": "stderr", "text": "/gpfs/fs01/user/s34f-24c5585e483e16-c0ce2641d0ef/.local/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n  \"This module will be removed in 0.20.\", DeprecationWarning)\n"}], "metadata": {}}, {"source": "## Handle Imbalance using SMOTE(only on Training set)", "cell_type": "markdown", "metadata": {}}, {"source": "# restart kernel if see error\nfrom imblearn.over_sampling import SMOTE", "cell_type": "code", "execution_count": 5, "outputs": [], "metadata": {}}, {"source": "X_train_dummy = pd.get_dummies(X_train)\nsm = SMOTE(random_state=2662761, ratio = 'auto', k_neighbors = 5)\nX_train_res, y_train_res = sm.fit_sample(X_train_dummy, y_train)\n\n\nprint('Fraud/Non-Fraud Ratio Before SMOTE: ' + str(y_train.sum()/len(y_train)))\nprint('Fraud/Non-Fraud Ratio After SMOTE: ' + str(y_train_res.sum()/len(y_train_res)))\n\nprint(\"Fraud in Training after SMOTE = T: \" + str(sum(y_train_res)))\nprint(\"Fraud in Training after SMOTE = F: \" + str(len(y_train_res) - sum(y_train_res)))\nprint(\"\\n************Test Set************\\n\")\nprint(\"Number of testing records : \" + str(len(X_test)))\nprint(\"Training: T = : \" + str(sum(y_test)))\nprint(\"Training: F = :\" + str(len(y_test) - sum(y_test)))", "cell_type": "code", "execution_count": 6, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Fraud/Non-Fraud Ratio Before SMOTE: 0.05233033524121014\nFraud/Non-Fraud Ratio After SMOTE: 0.5\nFraud in Training after SMOTE = T: 41724\nFraud in Training after SMOTE = F: 41724\n\n************Test Set************\n\nNumber of testing records : 11007\nTraining: T = : 599\nTraining: F = :10408\n"}], "metadata": {}}, {"source": "## XGboost\n\nThe hyperparameters are set as following, the same as Modeler's setting.", "cell_type": "markdown", "metadata": {}}, {"source": "xgb_model = XGBClassifier(\n    tree_method= \"auto\",\n    n_estimators = 10,\n    max_depth = 6,\n    min_child_weight = 1.0,\n    max_delta_step = 0.0,\n    objective = \"binary:logistic\",\n    seed = 6924827,\n    subsample = 1.0,\n    learning_rate = .3,\n    gamma = 0.0,\n    colsample_bytree = 1.0,\n    colsample_bylevel = 1.0,\n    reg_lambda = 1.0,\n    reg_alpha = 0.0,\n    scale_pos_weight = 1.0)", "cell_type": "code", "execution_count": 7, "outputs": [], "metadata": {}}, {"source": "xgb_model.fit(X_train_res, y_train_res, eval_set = [(X_train_res, y_train_res), (pd.get_dummies(X_test).as_matrix(), y_test)], eval_metric = \"auc\", verbose = True)", "cell_type": "code", "execution_count": 8, "outputs": [{"output_type": "stream", "name": "stdout", "text": "[0]\tvalidation_0-auc:0.893968\tvalidation_1-auc:0.641551\n[1]\tvalidation_0-auc:0.916541\tvalidation_1-auc:0.649042\n[2]\tvalidation_0-auc:0.947808\tvalidation_1-auc:0.65575\n[3]\tvalidation_0-auc:0.956587\tvalidation_1-auc:0.653419\n[4]\tvalidation_0-auc:0.967039\tvalidation_1-auc:0.647911\n[5]\tvalidation_0-auc:0.969599\tvalidation_1-auc:0.65116\n[6]\tvalidation_0-auc:0.972861\tvalidation_1-auc:0.654913\n[7]\tvalidation_0-auc:0.975912\tvalidation_1-auc:0.652043\n[8]\tvalidation_0-auc:0.977395\tvalidation_1-auc:0.651779\n[9]\tvalidation_0-auc:0.978747\tvalidation_1-auc:0.655097\n"}, {"output_type": "execute_result", "data": {"text/plain": "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,\n       colsample_bytree=1.0, gamma=0.0, learning_rate=0.3,\n       max_delta_step=0.0, max_depth=6, min_child_weight=1.0, missing=None,\n       n_estimators=10, n_jobs=1, nthread=None,\n       objective='binary:logistic', random_state=0, reg_alpha=0.0,\n       reg_lambda=1.0, scale_pos_weight=1.0, seed=6924827, silent=True,\n       subsample=1.0, tree_method='auto')"}, "execution_count": 8, "metadata": {}}], "metadata": {}}, {"source": "pred_classifier = xgb_model.predict(pd.get_dummies(X_test).as_matrix())", "cell_type": "code", "execution_count": 9, "outputs": [{"output_type": "stream", "name": "stderr", "text": "/gpfs/fs01/user/s34f-24c5585e483e16-c0ce2641d0ef/.local/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n  if diff:\n"}], "metadata": {}}, {"source": "roc = roc_auc_score(y_test, pred_classifier, )\nprint(\"ROC: \" +  str(roc))", "cell_type": "code", "execution_count": 10, "outputs": [{"output_type": "stream", "name": "stdout", "text": "ROC: 0.5005945246946294\n"}], "metadata": {}}, {"source": "## Using SMOTE output from SPSS\n\nTo control the randomness from Train/Test split and SMOTE, we tried using the SMOTE output from SPSS directly.", "cell_type": "markdown", "metadata": {}}, {"source": "SMOTEoutput = pd.read_csv(get_object_storage_file_with_credentials_79f48b7520e04b748bcd13ec11f1f911('Defaultproject', 'modeler_smoteout.csv'))\nSMOTEoutput = SMOTEoutput.drop(['Account_Number','Transaction_Time', 'last transaction time', 'Hours Since Last Transaction', 'Transaction_Dates',\t'Last_Trasaction_Dates'], 1)\n\n\nSMOTEoutput.head()", "cell_type": "code", "execution_count": 14, "outputs": [{"output_type": "execute_result", "data": {"text/plain": "   Dollar_Amount Transaction_Type                               Store_Type  \\\n0         188.56           swiped                           ATM Withdrawal   \n1         160.54            keyed                                  Grocery   \n2         153.24           swiped                        Retail - Pharmacy   \n3         148.66            keyed  Communications - telephone and wireless   \n4         174.03            keyed                               Spa/Beauty   \n\n  Cardholder_Region         Country Fraudulent  Last3hourTransactions  \\\n0                 E             USA          F                      4   \n1                NE       Australia          F                      3   \n2                SW  European Union          T                      2   \n3                NW             USA          F                      1   \n4                SW            Asia          F                      1   \n\n   Hours_Since_Last_Transaction   Partition  \n0                            21  1_Training  \n1                            21  1_Training  \n2                            21  1_Training  \n3                            35   2_Testing  \n4                            25  1_Training  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dollar_Amount</th>\n      <th>Transaction_Type</th>\n      <th>Store_Type</th>\n      <th>Cardholder_Region</th>\n      <th>Country</th>\n      <th>Fraudulent</th>\n      <th>Last3hourTransactions</th>\n      <th>Hours_Since_Last_Transaction</th>\n      <th>Partition</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>188.56</td>\n      <td>swiped</td>\n      <td>ATM Withdrawal</td>\n      <td>E</td>\n      <td>USA</td>\n      <td>F</td>\n      <td>4</td>\n      <td>21</td>\n      <td>1_Training</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>160.54</td>\n      <td>keyed</td>\n      <td>Grocery</td>\n      <td>NE</td>\n      <td>Australia</td>\n      <td>F</td>\n      <td>3</td>\n      <td>21</td>\n      <td>1_Training</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>153.24</td>\n      <td>swiped</td>\n      <td>Retail - Pharmacy</td>\n      <td>SW</td>\n      <td>European Union</td>\n      <td>T</td>\n      <td>2</td>\n      <td>21</td>\n      <td>1_Training</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>148.66</td>\n      <td>keyed</td>\n      <td>Communications - telephone and wireless</td>\n      <td>NW</td>\n      <td>USA</td>\n      <td>F</td>\n      <td>1</td>\n      <td>35</td>\n      <td>2_Testing</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>174.03</td>\n      <td>keyed</td>\n      <td>Spa/Beauty</td>\n      <td>SW</td>\n      <td>Asia</td>\n      <td>F</td>\n      <td>1</td>\n      <td>25</td>\n      <td>1_Training</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "execution_count": 14, "metadata": {}}], "metadata": {}}, {"source": "train = SMOTEoutput[SMOTEoutput.Partition == \"1_Training\"].drop('Partition', 1)\ntest = SMOTEoutput[SMOTEoutput.Partition == \"2_Testing\"].drop('Partition', 1)\n\ny = train['Fraudulent'].map(lambda l: 1 if l == 'T' else 0)\nX = pd.get_dummies(train.drop(['Fraudulent'], axis=1))\n\ny_test_spss = test['Fraudulent'].map(lambda l: 1 if l == 'T' else 0)\nX_test_spss = pd.get_dummies(test.drop(['Fraudulent'], axis=1))", "cell_type": "code", "execution_count": 22, "outputs": [], "metadata": {}}, {"source": "xgb_model2 = XGBClassifier(\n    tree_method= \"auto\",\n    n_estimators = 10,\n    max_depth = 6,\n    min_child_weight = 1.0,\n    max_delta_step = 0.0,\n    objective = \"binary:logistic\",\n    seed = 6924827,\n    subsample = 1.0,\n    learning_rate = .3,\n    gamma = 0.0,\n    colsample_bytree = 1.0,\n    colsample_bylevel = 1.0,\n    reg_lambda = 1.0,\n    reg_alpha = 0.0,\n    scale_pos_weight = 1.0)\nxgb_model2.fit(X.as_matrix(), y, eval_set = [(X.as_matrix(), y), (X_test_spss.as_matrix(), y_test_spss)], eval_metric = \"auc\", verbose = True)", "cell_type": "code", "execution_count": 24, "outputs": [{"output_type": "stream", "name": "stdout", "text": "[0]\tvalidation_0-auc:0.741852\tvalidation_1-auc:0.600351\n[1]\tvalidation_0-auc:0.75262\tvalidation_1-auc:0.599793\n[2]\tvalidation_0-auc:0.759496\tvalidation_1-auc:0.606255\n[3]\tvalidation_0-auc:0.762706\tvalidation_1-auc:0.608371\n[4]\tvalidation_0-auc:0.766306\tvalidation_1-auc:0.607905\n[5]\tvalidation_0-auc:0.771224\tvalidation_1-auc:0.609184\n[6]\tvalidation_0-auc:0.775101\tvalidation_1-auc:0.60665\n[7]\tvalidation_0-auc:0.778528\tvalidation_1-auc:0.600136\n[8]\tvalidation_0-auc:0.781652\tvalidation_1-auc:0.598593\n[9]\tvalidation_0-auc:0.784641\tvalidation_1-auc:0.599681\n"}, {"output_type": "execute_result", "data": {"text/plain": "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,\n       colsample_bytree=1.0, gamma=0.0, learning_rate=0.3,\n       max_delta_step=0.0, max_depth=6, min_child_weight=1.0, missing=None,\n       n_estimators=10, n_jobs=1, nthread=None,\n       objective='binary:logistic', random_state=0, reg_alpha=0.0,\n       reg_lambda=1.0, scale_pos_weight=1.0, seed=6924827, silent=True,\n       subsample=1.0, tree_method='auto')"}, "execution_count": 24, "metadata": {}}], "metadata": {}}, {"source": "pred_classifier_spssoutput = xgb_model2.predict(X_test_spss.as_matrix())", "cell_type": "code", "execution_count": 25, "outputs": [{"output_type": "stream", "name": "stderr", "text": "/gpfs/fs01/user/s34f-24c5585e483e16-c0ce2641d0ef/.local/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n  if diff:\n"}], "metadata": {}}, {"source": "roc2 = roc_auc_score(y_test_spss, pred_classifier_spssoutput)\nprint(\"ROC: \" +  str(roc2))", "cell_type": "code", "execution_count": 28, "outputs": [{"output_type": "stream", "name": "stdout", "text": "ROC: 0.5586843324628064\n"}], "metadata": {}}, {"source": "Still the ROC is different. ", "cell_type": "markdown", "metadata": {}}, {"source": "## Appendix\n\nSome screenshots from SPSS:\n<img src=\"https://github.com/CatherineCao2016/pics/raw/master/xgb_modeler_1.png\" width=\"500\" height=\"200\" align=\"middle\"/>\n<img src=\"https://github.com/CatherineCao2016/pics/raw/master/xgb_modeler_2.png\" width=\"400\" height=\"200\" align=\"middle\"/>\n<img src=\"https://github.com/CatherineCao2016/pics/raw/master/xgb_modeler_3.png\" width=\"400\" height=\"200\" align=\"middle\"/>\n<img src=\"https://github.com/CatherineCao2016/pics/raw/master/xgb_modeler_4.png\" width=\"400\" height=\"200\" align=\"middle\"/>\n<img src=\"https://github.com/CatherineCao2016/pics/raw/master/xgb_modeler_5.png\" width=\"400\" height=\"200\" align=\"middle\"/>", "cell_type": "markdown", "metadata": {}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Python 3.5 with Spark 2.1", "name": "python3-spark21", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "3.5.4", "name": "python", "pygments_lexer": "ipython3", "file_extension": ".py", "codemirror_mode": {"version": 3, "name": "ipython"}}}}